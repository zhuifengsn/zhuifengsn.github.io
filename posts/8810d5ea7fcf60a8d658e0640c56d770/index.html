<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【深度学习】二维CNN卷积手动实现(单/多输入单/多输出通道) - 追风少年的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【深度学习】二维CNN卷积手动实现(单/多输入单/多输出通道)" />
<meta property="og:description" content="单输入单输出通道 # 手动实现卷积 单输出单输入通道 def my_conv2d(input_feature_map, kernel, stride=1, padding=0, bias=0): if padding &gt; 0: input_feature_map = F.pad(input_feature_map, (padding, padding, padding, padding)) print(input_feature_map) input_h, input_w = input_feature_map.shape kernel_h, kernel_w = kernel.shape output_w = math.floor((input_w - kernel_w &#43; padding &#43; stride) / stride) # 卷积输出的宽度 output_h = math.floor((input_h - kernel_h &#43; padding &#43; stride) / stride) # 卷积输出的高度 # 可见 要想 输出和输入的feature map大小相同则需要 将padding = kernel_w - 1 print(f&#34;output_h:{output_h}, output_w:{output_w}&#34;) output = torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zhuifengsn.github.io/posts/8810d5ea7fcf60a8d658e0640c56d770/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-13T09:16:19+08:00" />
<meta property="article:modified_time" content="2022-06-13T09:16:19+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="追风少年的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">追风少年的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【深度学习】二维CNN卷积手动实现(单/多输入单/多输出通道)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>单输入单输出通道</h2> 
<pre><code class="prism language-python"><span class="token comment"># 手动实现卷积 单输出单输入通道</span>
<span class="token keyword">def</span> <span class="token function">my_conv2d</span><span class="token punctuation">(</span>input_feature_map<span class="token punctuation">,</span> kernel<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> padding <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
        input_feature_map <span class="token operator">=</span> F<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>input_feature_map<span class="token punctuation">,</span> <span class="token punctuation">(</span>padding<span class="token punctuation">,</span> padding<span class="token punctuation">,</span> padding<span class="token punctuation">,</span> padding<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>input_feature_map<span class="token punctuation">)</span>

    input_h<span class="token punctuation">,</span> input_w <span class="token operator">=</span> input_feature_map<span class="token punctuation">.</span>shape
    kernel_h<span class="token punctuation">,</span> kernel_w <span class="token operator">=</span> kernel<span class="token punctuation">.</span>shape

    output_w <span class="token operator">=</span> math<span class="token punctuation">.</span>floor<span class="token punctuation">(</span><span class="token punctuation">(</span>input_w <span class="token operator">-</span> kernel_w <span class="token operator">+</span> padding <span class="token operator">+</span> stride<span class="token punctuation">)</span> <span class="token operator">/</span> stride<span class="token punctuation">)</span>  <span class="token comment"># 卷积输出的宽度</span>
    output_h <span class="token operator">=</span> math<span class="token punctuation">.</span>floor<span class="token punctuation">(</span><span class="token punctuation">(</span>input_h <span class="token operator">-</span> kernel_h <span class="token operator">+</span> padding <span class="token operator">+</span> stride<span class="token punctuation">)</span> <span class="token operator">/</span> stride<span class="token punctuation">)</span>  <span class="token comment"># 卷积输出的高度</span>
    <span class="token comment"># 可见 要想 输出和输入的feature map大小相同则需要 将padding = kernel_w - 1</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"output_h:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>output_h<span class="token punctuation">}</span></span><span class="token string">, output_w:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>output_w<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>output_h<span class="token punctuation">,</span> output_w<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> input_h<span class="token operator">-</span>kernel_h<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> input_w<span class="token operator">-</span>kernel_w<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>
            region <span class="token operator">=</span> input_feature_map<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span>kernel_h<span class="token punctuation">,</span> j<span class="token punctuation">:</span>j<span class="token operator">+</span>kernel_w<span class="token punctuation">]</span>  <span class="token comment"># 取出和kernel相同大小的区域在feature map中</span>
            output<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>i <span class="token operator">/</span> stride<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>j <span class="token operator">/</span> stride<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>region<span class="token punctuation">,</span> kernel<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> bias
    
    <span class="token keyword">return</span> output 
</code></pre> 
<h3><a id="%09nnfunctionalconv2d_24"></a>与<code> nn.functional.conv2d</code>比较</h3> 
<pre><code class="prism language-python">input_feature_map <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
kernel <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
stride <span class="token operator">=</span> <span class="token number">2</span>
padding <span class="token operator">=</span> <span class="token number">0</span>
bias <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 和输出通道数维度相同 此处默认是1</span>
<span class="token comment"># 手动实现 默认输出通道为1</span>
output_feature_map <span class="token operator">=</span> my_conv2d<span class="token punctuation">(</span>input_feature_map<span class="token punctuation">,</span> kernel<span class="token punctuation">,</span> stride<span class="token punctuation">,</span> padding<span class="token punctuation">,</span> bias<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output_feature_map<span class="token punctuation">)</span>

<span class="token comment"># pytorch API</span>
output_api <span class="token operator">=</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>input_feature_map<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                        kernel<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> padding<span class="token operator">=</span>padding<span class="token punctuation">,</span> bias<span class="token operator">=</span>bias<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output_api<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_41"></a>结果</h3> 
<pre><code class="prism language-python">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">3.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">4.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">3.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">3.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">3.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
output_h<span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> output_w<span class="token punctuation">:</span><span class="token number">2</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">19.1882</span><span class="token punctuation">,</span> <span class="token number">17.1882</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">23.1882</span><span class="token punctuation">,</span> <span class="token number">19.1882</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">19.1882</span><span class="token punctuation">,</span> <span class="token number">17.1882</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">23.1882</span><span class="token punctuation">,</span> <span class="token number">19.1882</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="_55"></a>多输入多输出通道</h2> 
<pre><code class="prism language-python"><span class="token comment"># 多输入多输出通道</span>
<span class="token keyword">import</span> math
<span class="token comment"># 手动实现卷积 (batch_size, C, H, W)</span>
<span class="token keyword">def</span> <span class="token function">my_conv2d</span><span class="token punctuation">(</span>input_feature_map<span class="token punctuation">,</span> kernel<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> padding <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
        input_feature_map <span class="token operator">=</span> F<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>input_feature_map<span class="token punctuation">,</span> <span class="token punctuation">(</span>padding<span class="token punctuation">,</span> padding<span class="token punctuation">,</span> padding<span class="token punctuation">,</span> padding<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>input_feature_map<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># 从最后的维度开始进行pad 比如（3, 5, 5）就先从第三维度开始pad 按照提供的元组大size/2=需要pad的维度个数 一个维度两个pad长度值(前后)，默认pad 0</span>

    B<span class="token punctuation">,</span> _<span class="token punctuation">,</span> input_h<span class="token punctuation">,</span> input_w <span class="token operator">=</span> input_feature_map<span class="token punctuation">.</span>shape
    out_channels<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> kernel_h<span class="token punctuation">,</span> kernel_w <span class="token operator">=</span> kernel<span class="token punctuation">.</span>shape

    output_w <span class="token operator">=</span> math<span class="token punctuation">.</span>floor<span class="token punctuation">(</span><span class="token punctuation">(</span>input_w <span class="token operator">-</span> kernel_w <span class="token operator">+</span> padding <span class="token operator">+</span> stride<span class="token punctuation">)</span> <span class="token operator">/</span> stride<span class="token punctuation">)</span>  <span class="token comment"># 卷积输出的宽度</span>
    output_h <span class="token operator">=</span> math<span class="token punctuation">.</span>floor<span class="token punctuation">(</span><span class="token punctuation">(</span>input_h <span class="token operator">-</span> kernel_h <span class="token operator">+</span> padding <span class="token operator">+</span> stride<span class="token punctuation">)</span> <span class="token operator">/</span> stride<span class="token punctuation">)</span>  <span class="token comment"># 卷积输出的高度</span>
    <span class="token comment"># 可见 要想 输出和输入的feature map大小相同则需要 将padding = kernel_w - 1</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"output_h:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>output_h<span class="token punctuation">}</span></span><span class="token string">, output_w:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>output_w<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>B<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> output_h<span class="token punctuation">,</span> output_w<span class="token punctuation">)</span>

    <span class="token keyword">for</span> b <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> out_c <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> in_c <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> input_h<span class="token operator">-</span>kernel_h<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> input_w<span class="token operator">-</span>kernel_w<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>
                        <span class="token comment"># print(kernel[out_c, in_c, ...].shape)  # (K, K)</span>
                        region <span class="token operator">=</span> input_feature_map<span class="token punctuation">[</span>b<span class="token punctuation">,</span> in_c<span class="token punctuation">,</span> i<span class="token punctuation">:</span>i<span class="token operator">+</span>kernel_h<span class="token punctuation">,</span> j<span class="token punctuation">:</span>j<span class="token operator">+</span>kernel_w<span class="token punctuation">]</span>  <span class="token comment"># 取出和kernel相同大小的区域在feature map中</span>
                        <span class="token comment"># print(region.shape)  # (K, K)</span>
                        output<span class="token punctuation">[</span>b<span class="token punctuation">,</span> out_c<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>i <span class="token operator">/</span> stride<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>j <span class="token operator">/</span> stride<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+=</span> torch<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>region<span class="token punctuation">,</span> kernel<span class="token punctuation">[</span>out_c<span class="token punctuation">,</span> in_c<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
            output<span class="token punctuation">[</span>b<span class="token punctuation">,</span> out_c<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token operator">+=</span> bias<span class="token punctuation">[</span>out_c<span class="token punctuation">]</span>
    
    <span class="token keyword">return</span> output 
</code></pre> 
<h3><a id="nnfunctionalconv2d_87"></a>与<code>nn.functional.conv2d</code>比较</h3> 
<pre><code class="prism language-python">B <span class="token operator">=</span> batch_size <span class="token operator">=</span> <span class="token number">2</span>
C <span class="token operator">=</span> in_c <span class="token operator">=</span> in_channels <span class="token operator">=</span> <span class="token number">3</span>
H <span class="token operator">=</span> height <span class="token operator">=</span> <span class="token number">5</span>
W <span class="token operator">=</span> weight <span class="token operator">=</span> <span class="token number">5</span>
input_feature_map <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>B<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
K <span class="token operator">=</span> kernel_size <span class="token operator">=</span> <span class="token number">3</span>
out_c <span class="token operator">=</span> out_channels <span class="token operator">=</span> <span class="token number">2</span>
kernel <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>out_c<span class="token punctuation">,</span> in_c<span class="token punctuation">,</span> K<span class="token punctuation">,</span> K<span class="token punctuation">)</span>
stride <span class="token operator">=</span> <span class="token number">2</span>
padding <span class="token operator">=</span> <span class="token number">1</span>
bias <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>out_c<span class="token punctuation">)</span>  <span class="token comment"># 和输出通道数维度相同</span>
<span class="token comment"># print(bias)</span>

<span class="token comment"># 手动实现</span>
output_feature_map <span class="token operator">=</span> my_conv2d<span class="token punctuation">(</span>input_feature_map<span class="token punctuation">,</span> kernel<span class="token punctuation">,</span> stride<span class="token punctuation">,</span> padding<span class="token punctuation">,</span> bias<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output_feature_map<span class="token punctuation">)</span>

<span class="token comment"># pytorch API funcitonal</span>
api_output_feature_map <span class="token operator">=</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>input_feature_map<span class="token punctuation">,</span> kernel<span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> padding<span class="token operator">=</span>padding<span class="token punctuation">,</span> bias<span class="token operator">=</span>bias<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>api_output_feature_map<span class="token punctuation">)</span>

<span class="token comment"># class Conv2d</span>
<span class="token comment"># conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size, bias=False)</span>
<span class="token comment"># output_fm = conv_layer(input_feature_map)</span>
<span class="token comment"># print(output_fm.shape)</span>
<span class="token comment"># print(conv_layer.weight.shape)  # kernel 的大小和 batch_size 无关</span>
</code></pre> 
<h3><a id="_116"></a>结果</h3> 
<pre><code class="prism language-python">torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
output_h<span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">,</span> output_w<span class="token punctuation">:</span><span class="token number">3</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">13.8990</span><span class="token punctuation">,</span> <span class="token number">25.8990</span><span class="token punctuation">,</span> <span class="token number">20.8990</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">27.8990</span><span class="token punctuation">,</span> <span class="token number">46.8990</span><span class="token punctuation">,</span> <span class="token number">28.8990</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">23.8990</span><span class="token punctuation">,</span> <span class="token number">33.8990</span><span class="token punctuation">,</span> <span class="token number">17.8990</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">11.8909</span><span class="token punctuation">,</span> <span class="token number">23.8909</span><span class="token punctuation">,</span> <span class="token number">18.8909</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">25.8909</span><span class="token punctuation">,</span> <span class="token number">44.8909</span><span class="token punctuation">,</span> <span class="token number">26.8909</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">21.8909</span><span class="token punctuation">,</span> <span class="token number">31.8909</span><span class="token punctuation">,</span> <span class="token number">15.8909</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>


        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">21.8990</span><span class="token punctuation">,</span> <span class="token number">32.8990</span><span class="token punctuation">,</span> <span class="token number">21.8990</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">43.8990</span><span class="token punctuation">,</span> <span class="token number">68.8990</span><span class="token punctuation">,</span> <span class="token number">43.8990</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">23.8990</span><span class="token punctuation">,</span> <span class="token number">42.8990</span><span class="token punctuation">,</span> <span class="token number">31.8990</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">19.8909</span><span class="token punctuation">,</span> <span class="token number">30.8909</span><span class="token punctuation">,</span> <span class="token number">19.8909</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">41.8909</span><span class="token punctuation">,</span> <span class="token number">66.8909</span><span class="token punctuation">,</span> <span class="token number">41.8909</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">21.8909</span><span class="token punctuation">,</span> <span class="token number">40.8909</span><span class="token punctuation">,</span> <span class="token number">29.8909</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">13.8990</span><span class="token punctuation">,</span> <span class="token number">25.8990</span><span class="token punctuation">,</span> <span class="token number">20.8990</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">27.8990</span><span class="token punctuation">,</span> <span class="token number">46.8990</span><span class="token punctuation">,</span> <span class="token number">28.8990</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">23.8990</span><span class="token punctuation">,</span> <span class="token number">33.8990</span><span class="token punctuation">,</span> <span class="token number">17.8990</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">11.8909</span><span class="token punctuation">,</span> <span class="token number">23.8909</span><span class="token punctuation">,</span> <span class="token number">18.8909</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">25.8909</span><span class="token punctuation">,</span> <span class="token number">44.8909</span><span class="token punctuation">,</span> <span class="token number">26.8909</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">21.8909</span><span class="token punctuation">,</span> <span class="token number">31.8909</span><span class="token punctuation">,</span> <span class="token number">15.8909</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>


        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">21.8990</span><span class="token punctuation">,</span> <span class="token number">32.8990</span><span class="token punctuation">,</span> <span class="token number">21.8990</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">43.8990</span><span class="token punctuation">,</span> <span class="token number">68.8990</span><span class="token punctuation">,</span> <span class="token number">43.8990</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">23.8990</span><span class="token punctuation">,</span> <span class="token number">42.8990</span><span class="token punctuation">,</span> <span class="token number">31.8990</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">19.8909</span><span class="token punctuation">,</span> <span class="token number">30.8909</span><span class="token punctuation">,</span> <span class="token number">19.8909</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">41.8909</span><span class="token punctuation">,</span> <span class="token number">66.8909</span><span class="token punctuation">,</span> <span class="token number">41.8909</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">21.8909</span><span class="token punctuation">,</span> <span class="token number">40.8909</span><span class="token punctuation">,</span> <span class="token number">29.8909</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="_153"></a>结论</h2> 
<p>由上述结果可看出，手动实现主要是依赖循环实现，需要注意的是，在手动实现过程中<strong>输出特征图</strong>形状的计算方式，以及bias的维度(bias的维度是输出通道的维度，也就是输出特征图每个通道特征图分配一个bias标量值，然后特征图的每个像素值都加相同的bias)。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/cb13b1b4da6232db23f860ff55efff9d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">后端接收参数为Date，用postman怎么传？</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/daead2ceeb01f06f4e8886c6e1fd74c0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">如何使用IDEA 启动war包maven项目</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 追风少年的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>