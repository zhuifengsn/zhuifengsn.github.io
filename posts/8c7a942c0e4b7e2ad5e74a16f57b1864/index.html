<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>scikit-learn机器学习终结，拿走不谢 - 追风少年的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="scikit-learn机器学习终结，拿走不谢" />
<meta property="og:description" content="#导入需要的库
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction import DictVectorizer
from sklearn.preprocessing import MinMaxScaler,StandardScaler
from sklearn.feature_selection import VarianceThreshold
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier,export_graphviz
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC, NuSVC, LinearSVC
from sklearn.datasets import fetch_20newsgroups,load_boston
from sklearn.metrics import ConfusionMatrixDisplay,accuracy_score,roc_curve, auc,mean_squared_error,silhouette_score
from sklearn.multiclass import OneVsRestClassifier
from sklearn.linear_model import LinearRegression,SGDRegressor,Ridge,RidgeCV,LogisticRegression
from sklearn.neural_network import MLPRegressor,MLPClassifier
from sklearn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zhuifengsn.github.io/posts/8c7a942c0e4b7e2ad5e74a16f57b1864/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-08-31T17:14:22+08:00" />
<meta property="article:modified_time" content="2022-08-31T17:14:22+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="追风少年的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">追风少年的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">scikit-learn机器学习终结，拿走不谢</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p></p> 
<p>#导入需要的库</p> 
<p>from sklearn.feature_extraction.text import CountVectorizer<br> from sklearn.model_selection import train_test_split<br> from sklearn.feature_extraction import DictVectorizer<br> from sklearn.preprocessing import MinMaxScaler,StandardScaler<br> from sklearn.feature_selection import VarianceThreshold<br> from sklearn.model_selection import GridSearchCV<br> from sklearn.neighbors import KNeighborsClassifier<br> from sklearn.naive_bayes import MultinomialNB<br> from sklearn.tree import DecisionTreeClassifier,export_graphviz<br> from sklearn.ensemble import RandomForestClassifier<br> from sklearn.svm import SVC, NuSVC, LinearSVC<br> from sklearn.datasets import fetch_20newsgroups,load_boston<br> from sklearn.metrics import ConfusionMatrixDisplay,accuracy_score,roc_curve, auc,mean_squared_error,silhouette_score<br> from sklearn.multiclass import OneVsRestClassifier<br> from sklearn.linear_model import LinearRegression,SGDRegressor,Ridge,RidgeCV,LogisticRegression<br> from sklearn.neural_network import MLPRegressor,MLPClassifier<br> from sklearn.cluster import KMeans<br> from sklearn.decomposition import PCA<br> from tensorflow.keras import models,Model,layers,losses,metrics,callbacks <br> import tensorflow as tf<br> import jieba as jb <br> import pandas as pd<br> import numpy as np <br> from  random import shuffle<br> import matplotlib.pyplot as plt<br> # KNN算法<br> def KNN_Algorithm():<br>     """<br>     K近邻算法预测入住位置类别<br>     :return:<br>     """<br>     # 一、处理数据以及特征工程<br>     # 1、读取收，缩小数据的范围</p> 
<p>    data = pd.read_csv("D:/xueixixiangmu/Machine_Learning/resources/FBlocation/train.csv")<br>     # 数据逻辑筛选操作 df.query()<br>     data = data.query("x &gt; 1.0 &amp; x &lt; 1.25 &amp; y &gt; 2.5 &amp; y &lt; 2.75")<br>     # # 删除time这一列特征<br>     data = data.drop(['time'], axis=1)<br>     # # 删除入住次数少于三次位置<br>     place_count = data.groupby('place_id').count()<br>     place_count</p> 
<p>    tf = place_count[place_count.row_id &gt; 3].reset_index()<br>     data = data[data['place_id'].isin(tf.place_id)]<br>     # # 3、取出特征值和目标值<br>     y = data['place_id']<br>     # # y = data[['place_id']]<br>     x = data.drop(['place_id', 'row_id'], axis=1)<br>     # # 4、数据分割与特征工程?<br>     # # （1）、数据分割<br>     x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)<br>     # # (2)、标准化<br>     transfer=StandardScaler()<br>     # # 队训练集进行标准化操作<br>     x_train = transfer.fit_transform(x_train)<br>     # print(x_train)<br>     # # 进行测试集的标准化操作<br>     x_test = transfer.fit_transform(x_test)<br>     # # 二、算法的输入训练预测<br>     # # K值：算法传入参数不定的值    理论上：k = 根号(样本数)<br>     # # K值：后面会使用参数调优方法，去轮流试出最好的参数[1,3,5,10,20,100,200],实列化一个评估器<br>     knn = KNeighborsClassifier()<br>     parm={"n_neighbors":[3,5,10]}<br>     knn=GridSearchCV(knn,param_grid=parm,cv=2)<br>     knn.fit(x_train, y_train)<br>     print("选择了某个模型测试集当中预测的准确率为：", knn.score(x_test, y_test))<br>     # 训练验证集的结果<br>     print("在交叉验证当中验证的最好结果：", knn.best_score_)<br>     print("gc选择了的模型K值是：", knn.best_estimator_)<br>     print("每次交叉验证的结果为：", knn.cv_results_)<br>     print("预测测试集类别：", y_predict)<br>     return None<br> #朴树贝叶斯<br> def nbcls_Algorithm():<br>     """<br>     朴素贝叶斯对新闻数据集进行预测<br>     :return:<br>     """<br>     # 获取新闻的数据，20个类别<br>     news = fetch_20newsgroups(subset='all')<br>     # 进行数据集分割<br>     x_train, x_test, y_train, y_test = train_test_split(news.data, news.target, test_size=0.3)<br>     # 对于文本数据，进行特征抽取<br>     tf = TfidfVectorizer()<br>     x_train = tf.fit_transform(x_train)<br>     # # 这里打印出来的列表是：训练集当中的所有不同词的组成的一个列表<br>     # print(tf.get_feature_names())<br>     print(x_train.toarray())<br>     # 不能调用fit_transform<br>     x_test = tf.transform(x_test)<br>     # estimator估计器流程<br>     mlb = MultinomialNB(alpha=1.0)<br>     mlb.fit(x_train, y_train)<br>     # 进行预测<br>     y_predict = mlb.predict(x_test)<br>     print("预测每篇文章的类别：", y_predict[:100])<br>     print("真实类别为：", y_test[:100])<br>     print("预测准确率为：", mlb.score(x_test, y_test))<br>     return None<br> #决策树<br> def decisioncls_Algorithm():<br>     """<br>     决策树进行乘客生存预测<br>     :return:<br>     """<br>     # 1、获取数据<br>     titan = pd.read_csv("D:/xueixixiangmu/Machine_Learning/resources/titanic/titanic.csv")<br>     # 2、数据的处理<br>     x = titan[['pclass', 'age', 'sex']]<br>     y = titan['survived']<br>     # print(x , y)<br>     # 缺失值需要处理，将特征当中有类别的这些特征进行字典特征抽取<br>     x['age'].fillna(x['age'].mean(), inplace=True)<br>     # 对于x转换成字典数据<br>     # x.to_dict(orient="records")<br>     # # [{"pclass": "1st", "age": 29.00, "sex": "female"}, {}]<br>     dict = DictVectorizer(sparse=False)<br>     x = dict.fit_transform(x.to_dict(orient="records"))<br>     # print(dict.get_feature_names())<br>     # print(x)<br>     # 分割训练集合测试集<br>     x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)<br>     # 进行决策树的建立和预测<br>     dc = DecisionTreeClassifier(max_depth=5)<br>     dc.fit(x_train, y_train)<br>     print("预测的准确率为：", dc.score(x_test, y_test))<br>     <br>     return None<br> def RF__Algorithm():<br>     # 随机森林去进行预测生存预测<br>     titan = pd.read_csv("D:/xueixixiangmu/Machine_Learning/resources/titanic/titanic.csv")<br>     # 2、数据的处理<br>     x = titan[['pclass', 'age', 'sex']]<br>     y = titan['survived']<br>     # print(x , y)<br>     # 缺失值需要处理，将特征当中有类别的这些特征进行字典特征抽取<br>     x['age'].fillna(x['age'].mean(), inplace=True)<br>     # 对于x转换成字典数据<br>     # x.to_dict(orient="records")<br>     # # [{"pclass": "1st", "age": 29.00, "sex": "female"}, {}]<br>     dict = DictVectorizer(sparse=False)<br>     x = dict.fit_transform(x.to_dict(orient="records"))<br>     # print(dict.get_feature_names())<br>     # print(x)<br>     # 分割训练集合测试集<br>     x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)<br>     # 进行决策树的建立和预测<br>     rf = RandomForestClassifier()<br>     param = {"n_estimators": [120,200,300,500,800,1200], "max_depth": [5, 8, 15, 25, 30]}<br>     # 超参数调优<br>     gc = GridSearchCV(rf, param_grid=param, cv=2)<br>     gc.fit(x_train, y_train)<br>     print("随机森林预测的准确率为：", gc.score(x_test, y_test))<br>     return None<br> def SVM_Algorithm():<br>     """<br>     支持向量机进行乘客生存预测<br>     :return:<br>     """<br>     # 1、获取数据<br>     titan = pd.read_csv("D:/xueixixiangmu/Machine_Learning/resources/titanic/titanic.csv")<br>     # 2、数据的处理<br>     x = titan[['pclass', 'age', 'sex']]<br>     y = titan['survived']<br>     # print(x , y)<br>     # 缺失值需要处理，将特征当中有类别的这些特征进行字典特征抽取<br>     x['age'].fillna(x['age'].mean(), inplace=True)<br>     # 对于x转换成字典数据<br>     # x.to_dict(orient="records")<br>     # # [{"pclass": "1st", "age": 29.00, "sex": "female"}, {}]<br>     dict = DictVectorizer(sparse=False)<br>     x = dict.fit_transform(x.to_dict(orient="records"))<br>     # print(dict.get_feature_names())<br>     # print(x)<br>     # 分割训练集合测试集<br>     x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)<br>     # 进行支持向量机预估器建立<br>     random_state = np.random.RandomState(0)<br>     classifier = OneVsRestClassifier(svm.SVC(kernel="linear", probability=True, random_state=random_state))<br>     y_score = classifier.fit(x_train, y_train).decision_function(x_test)<br>     y_predict = classifier.fit(x_train, y_train).decision_function(x_test)<br>     fpr = {}<br>     tpr = {}<br>     roc_auc ={}<br>     fpr["1"], tpr["1"], _ = roc_curve(y_test[:], y_predict[:])<br>     roc_auc["1"] = auc(fpr["1"], tpr["1"])<br>     fpr["2"], tpr["2"], _ = roc_curve(y_test.ravel(), y_predict.ravel())<br>     roc_auc["2"] = auc(fpr["2"], tpr["2"])<br>     plt.figure()<br>     lw = 2<br>     plt.plot(<br>         fpr["1"],<br>         tpr["1"],<br>         color="darkorange",<br>         lw=lw,<br>         label="ROC curve (area = %0.2f)" % roc_auc["1"],<br>     )<br>     plt.plot([0, 1], [0, 1], color="navy", lw=lw, linestyle="--")<br>     plt.xlim([0.0, 1.0])<br>     plt.ylim([0.0, 1.05])<br>     plt.xlabel("False Positive Rate")<br>     plt.ylabel("True Positive Rate")<br>     plt.title("Receiver operating characteristic example")<br>     plt.legend(loc="lower right")<br>     plt.show()<br>     print("预测的准确率为：", classifier.score(x_test, y_test))<br>     return None<br> #正规方程随机梯度下降<br> def mylinearregression():<br>     lb = load_boston()<br>     # print(lb.data)<br>     # print(lb.target)<br>     # 对数据集进行划分<br>     x_train, x_test, y_train, y_test = train_test_split(lb.data, lb.target, test_size=0.3, random_state=24)<br>     # # 需要做标准化处理对于特征值处理<br>     std_x = StandardScaler()<br>     x_train = std_x.fit_transform(x_train)<br>     x_test = std_x.fit_transform(x_test)<br>     # # print(x_train)<br>     # # 对于目标值进行标准化<br>     # std_y = StandardScaler()<br>     # y_train = std_x.fit_transform(y_train)<br>     # y_test = std_x.transform(y_test)<br>     # y_test = std_x.inverse_transform(y_test)<br>     # # 使用线性模型进行预测<br>     # # 使用正规方程求解<br>     lr = LinearRegression()<br>     # # 此时在干什么？<br>     lr.fit(x_train, y_train)<br>     y_lr_predict = lr.predict(x_test)<br>     print(lr.coef_)<br>     print("正规方程预测的结果为：", y_lr_predict)<br>     print("正规方程的均方误差为：", mean_squared_error(y_test, y_lr_predict))<br>     # 梯度下降进行预测<br>     sgd = SGDRegressor()<br>     sgd.fit(x_train, y_train)<br>     print("SGD的权重参数为：", sgd.coef_)<br>     y_sgd_predict = sgd.predict(x_test)<br>     print("SGD的预测的结果为：", y_sgd_predict)<br>     # # 怎么评判这两个方法好坏<br>     print("SGD的均方误差为：", mean_squared_error(y_test, y_sgd_predict))<br> #     #正则化，L2回归降低过拟合<br> #     rd = Ridge(alpha=1.0)<br> #     rd.fit(x_train, y_train)<br> #     print("岭回归的权重参数为：", rd.coef_)<br> #     y_rd_predict = std_y.inverse_transform(rd.predict(x_test))<br> #     print("岭回归的预测的结果为：", y_rd_predict)<br> #     print("岭回归的均方误差为：", mean_squared_error(y_test, y_rd_predict))<br> def logisticregression_demo():<br>     """<br>     逻辑回归进行癌症预测<br>     :return: None<br>     """<br>     # 1、读取数据，处理缺失值以及标准化<br>     column_name = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',<br>                    'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',<br>                    'Normal Nucleoli', 'Mitoses', 'Class']<br>     data = pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data",<br>                        names=column_name)<br>     # 删除缺失值<br>     data = data.replace(to_replace='?', value=np.nan)<br>     data = data.dropna()<br>     # 取出特征值<br>     x = data[column_name[1:10]]<br>     y = data[column_name[10]]<br>     # 分割数据集<br>     x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)<br>     # 进行标准化<br>     std = StandardScaler()<br>     x_train = std.fit_transform(x_train)<br>     x_test = std.transform(x_test)<br>     # 使用逻辑回归<br>     lr = LogisticRegression()<br>     lr.fit(x_train, y_train)<br>     print("得出来的权重：", lr.coef_)<br>     # 预测类别<br>     print("预测的类别：", lr.predict(x_test))<br>     # 得出准确率<br>     print("预测的准确率:", lr.score(x_test, y_test))<br>     #模型保存<br>     joblib.dump(lr, "path/保存路径")<br>     #模型加载<br>     model = joblib.load("test.pkl/模型")<br>     print("从文件加载进来的模型预测的结果：", std_y.inverse_transform(model.predict(x_test)))<br>     return None<br> def pca_demo():<br>     """<br>     对数据进行PCA降维<br>     :return: None<br>     """<br>     data = [[2,8,4,5], [6,3,0,8], [5,4,9,1]]<br>     # 1、实例化PCA, 小数——保留多少信息<br>     transfer = PCA(n_components=0.9)<br>     # 2、调用fit_transform<br>     data1 = transfer.fit_transform(data)<br>     pd.DataFrame(data1)<br>     # print("保留90%的信息，降维结果为：\n", data1)<br>     # 1、实例化PCA, 整数——指定降维到的维数<br>     transfer2 = PCA(n_components=3)<br>     # 2、调用fit_transform<br>     data2 = transfer2.fit_transform(data)<br>     # pd.DataFrame(data2)<br>     print("降维到3维的结果：\n", data2)<br>     return None<br> def Kmeans_demo ():<br>     data = [[2,8,4,5], [6,3,0,8], [5,4,9,1]]<br>     km = KMeans(n_clusters=2)<br>     km.fit(data)<br>     pre = km.predict(data)<br>     print(pre)<br>     print(silhouette_score(data ,pre))<br> def ANN_demo():<br>     #神经网络预测<br>     column_name = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',<br>                    'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',<br>                    'Normal Nucleoli', 'Mitoses', 'Class']<br>     data = pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data",<br>                        names=column_name)<br>     # 删除缺失值<br>     data = data.replace(to_replace='?', value=np.nan)<br>     data = data.dropna()<br>     # 取出特征值<br>     x = data[column_name[1:10]]<br>     y = data[column_name[10]]<br>     # 分割数据集<br>     x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)<br>     # 进行归一化<br>     std = MinMaxScaler()<br>     x_train = std.fit_transform(x_train)<br>     x_test = std.transform(x_test)<br>     mlp = MLPClassifier()<br>     mlp.fit(x_train, y_train)<br>     print("预测的类别：", mlp.predict(x_test))<br>     # 得出准确率<br>     print("预测的准确率:", mlp.score(x_test, y_test))<br>     return None<br> def DNN_Algorithm():<br>     """<br>     深度DNN进行乘客生存预测<br>     :return:<br>     """<br>     # 1、获取数据<br>     titan = pd.read_csv("D:/xueixixiangmu/Machine_Learning/resources/titanic/titanic.csv")<br>     # 2、数据的处理<br>     x = titan[['pclass', 'age', 'sex']]<br>     y = titan['survived']<br>     # print(x , y)<br>     # 缺失值需要处理，将特征当中有类别的这些特征进行字典特征抽取<br>     x['age'].fillna(x['age'].mean(), inplace=True)<br>     # 对于x转换成字典数据<br>     # x.to_dict(orient="records")<br>     # # [{"pclass": "1st", "age": 29.00, "sex": "female"}, {}]<br>     dict = DictVectorizer(sparse=False)<br>     x = dict.fit_transform(x.to_dict(orient="records"))<br>     # print(dict.get_feature_names())<br>     # print(x)<br>     # 分割训练集合测试集<br>     x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)<br>     #深度神经网络建立<br>     #     model=models.Sequential()</p> 
<p>    #     x_input = layers.Input(shape = (None,6))<br>     #     x=layers.LSTM(32)(x_input)<br>     #     x=layers.Dense(20,activation = 'relu')(x)<br>     #     x=layers.Dense(10,activation = 'relu' )(x)<br>     #     x=layers.Dense(1,activation = 'sigmoid' )(x)<br>     #     model = models.Model(inputs = x_input,outputs = x)<br>     #     model.summary()<br>     model=models.Sequential()<br>     model.add(layers.Dense(20,input_shape=(6,),activation = 'relu'))<br>     model.add(layers.Dense(10,activation = 'relu' ))<br>     model.add(layers.Dense(1,activation = 'sigmoid' ))<br>     model.summary()<br>     #     # 二分类问题选择二元交叉熵损失函数<br>     model.compile(optimizer="adam",loss="binary_crossentropy",<br>                  metrics=["Accuracy"])<br>     model.fit(x_train,y_train,batch_size=64,epochs=30,<br>              validation_split=0.2)</p> 
<p>    history = model.fit(x_train,y_train,<br>                         batch_size= 64,<br>                         epochs= 30,<br>                         validation_split=0.2 #分割一部分训练数据用于验证<br>                        )</p> 
<p>#     # # 进行决策树的建立和预测<br> #     # dc = DecisionTreeClassifier(max_depth=5)<br> #     # dc.fit(x_train, y_train)<br> #     print("预测的准确率为：", model.evaluate(x_test, y_test))<br> #     predict_x=model.predict(x_test) <br> #     predict_x<br> # #     classes_x=np.argmax(predict_x,axis=1)</p> 
<p># #     return None<br> # DNN_Algorithm()</p> 
<p><br>     <br> if __name__=="__main__":<br> # # # # # #     KNN_Algorithm()<br> # # # #      RF__Algorithm()<br> # # #      mylinearregression()<br> #     ANN_demo()</p> 
<p><br>     <br>  </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5f75f08d649737ab7bb8a6394b9f3f1f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">资源管理器占用CPU过高的解决方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/db14bd8b3076b8d60803be7cea2a8e3b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">python split 函数方法，字符串分割，分割中间，分割左右，分割次数。</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 追风少年的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>