<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>虚拟试穿代码理解Down to the Last Detail: Virtual Try-on with Fine-grained Details（demo.py上） - 追风少年的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="虚拟试穿代码理解Down to the Last Detail: Virtual Try-on with Fine-grained Details（demo.py上）" />
<meta property="og:description" content="文章目录 demo.py引用库：load\_model函数：forward函数（上）：模型初始化模块：数据增强模块：数据初始化模块： Down to the Last Detail: Virtual Try-on with Fine-grained Details, ACM MM 2020 Paper, Code/Model, ArXiv 深入到最后一个细节：能雕刻细节的虚拟试穿 理解得不对的地方欢迎评论区指正~ demo.py 引用库： torch：PyTorch的核心库，提供张量数据结构和数值计算操作等基本功能。torch.nn：PyTorch中神经网络模块的库，提供各种层和模型的定义和实现。models.networks：该脚本定义了自己的网络模型，其中包括Define_G和Define_D模型。torch.optim：PyTorch中优化算法的库，包括SGD、Adam、Adagrad、AdamW等优化器。config：一个Python脚本，定义了训练和测试的各种参数。os：提供了与操作系统交互的函数，用于访问文件系统等操作。os.path：提供了与路径相关的函数，用于处理文件和目录路径。torch.utils.data：PyTorch中数据加载和预处理的库，包括DataLoader等数据加载器。transforms：用于对图像进行变换的库，可以进行裁剪、缩放、旋转等操作。data.regular_dataset：一个Python脚本，定义了数据集类，用于读取和处理训练和测试数据。data.demo_dataset：一个Python脚本，定义了演示数据集类。utils.transforms：自定义的图像变换函数。time：Python的时间库，用于时间相关操作。datetime：Python的日期和时间库，用于日期和时间相关操作。torch.backends.cudnn：PyTorch针对GPU优化的库，用于提升训练速度。numpy：Python的数值计算库，提供了大量数学函数和矩阵操作。torchvision.utils：PyTorch中关于图像处理的工具函数。PIL.Image：Python的图像处理库，提供了图像读取、保存、缩放、旋转等操作。utils.pose_utils：自定义的人体姿态估计工具函数。torch.nn.functional：PyTorch中一些常用的函数库。lib.geometric_matching_multi_gpu：自定义的几何变换库，用于图像变形操作。cv2：Python中OpenCV库的接口，用于图像和视频处理 load_model函数： #load_model功能是加载预训练模型并返回预训练好的模型 def load_model(model, path): checkpoint = torch.load(path)#从指定路径（path）加载预训练模型（checkpoint） try: model.load_state_dict(checkpoint)#加载预训练模型的状态字典，以便将预训练模型的参数应用于该模型。 except: model.load_state_dict(checkpoint.state_dict())#如果出现加载不成功的情况，使用 checkpoint.state_dict() 来加载 model = model.cuda()#将模型加载到 GPU 中，以便后续在 GPU 上进行计算 model.eval()#将模型设置为测试模式，即关闭 dropout 和 batch normalization 等对模型参数的影响。 print(20*&#39;=&#39;) for param in model.parameters():#冻结模型参数，避免在预测时更新模型参数，节省计算资源。 param.requires_grad = False #状态字典（state dictionary）是指在深度学习模型中保存了模型所有可学习参数的字典，每个参数都对应一个键值对。 # 在 PyTorch 中，状态字典通常是由模型的 state_dict() 方法返回的，它包含了所有的权重、偏差等参数信息。 # 状态字典可以通过调用 load_state_dict() 方法加载到模型中，使得模型的权重与状态字典中保存的权重保持一致。 # 通常在保存和加载模型时会用到状态字典，以便能够准确地保存和加载模型的权重，方便进行模型的训练和推理。 #Dropout是一种在深度神经网络中使用的正则化技术，可以在训练过程中减少过拟合现象。 #Dropout在每个训练批次中随机地使一些神经元失活，即将它们的输出设置为0，从而使得每个神经元都有一定的概率被临时忽略。 # 通过这种方式，dropout可以迫使神经元们相互独立地学习，而不是互相依赖，从而防止模型对训练集的过拟合。 #Batch normalization (批量归一化)是一种常用的神经网络正则化技术，旨在减轻训练深度神经网络时的内部协变量偏移 (internal covariate shift) 问题。 #内部协变量偏移是指在训练过程中，网络内部每一层的输入分布会随着网络的参数不断变化而发生变化，导致训练过程变得困难。 #Batch normalization 将每个 batch 的输入进行标准化处理，使其均值为0，方差为1，从而减少输入分布的变化，缓解了内部协变量偏移问题。 #同时，Batch normalization 也可以使得网络更加稳定，提高模型的收敛速度和准确性。Batch normalization 通常在网络的激活函数之前应用。 forward函数（上）： 模型初始化模块： def forward(opt, paths, gpu_ids, refine_path):#opt包含了试穿的相关参数，paths包含了用于加载模型的路径，gpu_ids指定了使用的GPU ID，refine_path指定了渲染的参考图片的路径。 cudnn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zhuifengsn.github.io/posts/fa62a6d5a80b85c2f72d779788a3136d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-03T09:43:05+08:00" />
<meta property="article:modified_time" content="2023-03-03T09:43:05+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="追风少年的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">追风少年的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">虚拟试穿代码理解Down to the Last Detail: Virtual Try-on with Fine-grained Details（demo.py上）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#demopy_5" rel="nofollow">demo.py</a></li><li><ul><li><a href="#_6" rel="nofollow">引用库：</a></li><li><a href="#load_model_30" rel="nofollow">load\_model函数：</a></li><li><a href="#forward_60" rel="nofollow">forward函数（上）：</a></li><li><ul><li><a href="#_61" rel="nofollow">模型初始化模块：</a></li><li><a href="#_87" rel="nofollow">数据增强模块：</a></li><li><a href="#_114" rel="nofollow">数据初始化模块：</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<br> Down to the Last Detail: Virtual Try-on with Fine-grained Details, ACM MM 2020 
<br> 
<a href="https://dl.acm.org/doi/pdf/10.1145/3394171.3413514" rel="nofollow">Paper</a>, 
<a href="https://github.com/JDAI-CV/Down-to-the-Last-Detail-Virtual-Try-on-with-Detail-Carving">Code/Model</a>, 
<a href="https://arxiv.org/abs/1912.06324v2" rel="nofollow">ArXiv</a> 
<br> 深入到最后一个细节：能雕刻细节的虚拟试穿 
<br> 理解得不对的地方欢迎评论区指正~ 
<p></p> 
<h2><a id="demopy_5"></a>demo.py</h2> 
<h3><a id="_6"></a>引用库：</h3> 
<ul><li>torch：PyTorch的核心库，提供张量数据结构和数值计算操作等基本功能。</li><li>torch.nn：PyTorch中神经网络模块的库，提供各种层和模型的定义和实现。</li><li>models.networks：该脚本定义了自己的网络模型，其中包括Define_G和Define_D模型。</li><li>torch.optim：PyTorch中优化算法的库，包括SGD、Adam、Adagrad、AdamW等优化器。</li><li>config：一个Python脚本，定义了训练和测试的各种参数。</li><li>os：提供了与操作系统交互的函数，用于访问文件系统等操作。</li><li>os.path：提供了与路径相关的函数，用于处理文件和目录路径。</li><li>torch.utils.data：PyTorch中数据加载和预处理的库，包括DataLoader等数据加载器。</li><li>transforms：用于对图像进行变换的库，可以进行裁剪、缩放、旋转等操作。</li><li>data.regular_dataset：一个Python脚本，定义了数据集类，用于读取和处理训练和测试数据。</li><li>data.demo_dataset：一个Python脚本，定义了演示数据集类。</li><li>utils.transforms：自定义的图像变换函数。</li><li>time：Python的时间库，用于时间相关操作。</li><li>datetime：Python的日期和时间库，用于日期和时间相关操作。</li><li>torch.backends.cudnn：PyTorch针对GPU优化的库，用于提升训练速度。</li><li>numpy：Python的数值计算库，提供了大量数学函数和矩阵操作。</li><li>torchvision.utils：PyTorch中关于图像处理的工具函数。</li><li>PIL.Image：Python的图像处理库，提供了图像读取、保存、缩放、旋转等操作。</li><li>utils.pose_utils：自定义的人体姿态估计工具函数。</li><li>torch.nn.functional：PyTorch中一些常用的函数库。</li><li>lib.geometric_matching_multi_gpu：自定义的几何变换库，用于图像变形操作。</li><li>cv2：Python中OpenCV库的接口，用于图像和视频处理</li></ul> 
<h3><a id="load_model_30"></a>load_model函数：</h3> 
<pre><code class="prism language-python"><span class="token comment">#load_model功能是加载预训练模型并返回预训练好的模型</span>
<span class="token keyword">def</span> <span class="token function">load_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> path<span class="token punctuation">)</span><span class="token punctuation">:</span>

    checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token comment">#从指定路径（path）加载预训练模型（checkpoint）</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span><span class="token comment">#加载预训练模型的状态字典，以便将预训练模型的参数应用于该模型。</span>
    <span class="token keyword">except</span><span class="token punctuation">:</span>
        model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#如果出现加载不成功的情况，使用 checkpoint.state_dict() 来加载</span>
    model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#将模型加载到 GPU 中，以便后续在 GPU 上进行计算</span>

    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#将模型设置为测试模式，即关闭 dropout 和 batch normalization 等对模型参数的影响。</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token operator">*</span><span class="token string">'='</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#冻结模型参数，避免在预测时更新模型参数，节省计算资源。</span>
        param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>
<span class="token comment">#状态字典（state dictionary）是指在深度学习模型中保存了模型所有可学习参数的字典，每个参数都对应一个键值对。</span>
<span class="token comment"># 在 PyTorch 中，状态字典通常是由模型的 state_dict() 方法返回的，它包含了所有的权重、偏差等参数信息。</span>
<span class="token comment"># 状态字典可以通过调用 load_state_dict() 方法加载到模型中，使得模型的权重与状态字典中保存的权重保持一致。</span>
<span class="token comment"># 通常在保存和加载模型时会用到状态字典，以便能够准确地保存和加载模型的权重，方便进行模型的训练和推理。</span>

<span class="token comment">#Dropout是一种在深度神经网络中使用的正则化技术，可以在训练过程中减少过拟合现象。</span>
<span class="token comment">#Dropout在每个训练批次中随机地使一些神经元失活，即将它们的输出设置为0，从而使得每个神经元都有一定的概率被临时忽略。</span>
<span class="token comment"># 通过这种方式，dropout可以迫使神经元们相互独立地学习，而不是互相依赖，从而防止模型对训练集的过拟合。</span>

<span class="token comment">#Batch normalization (批量归一化)是一种常用的神经网络正则化技术，旨在减轻训练深度神经网络时的内部协变量偏移 (internal covariate shift) 问题。</span>
<span class="token comment">#内部协变量偏移是指在训练过程中，网络内部每一层的输入分布会随着网络的参数不断变化而发生变化，导致训练过程变得困难。</span>
<span class="token comment">#Batch normalization 将每个 batch 的输入进行标准化处理，使其均值为0，方差为1，从而减少输入分布的变化，缓解了内部协变量偏移问题。</span>
<span class="token comment">#同时，Batch normalization 也可以使得网络更加稳定，提高模型的收敛速度和准确性。Batch normalization 通常在网络的激活函数之前应用。</span>
</code></pre> 
<h3><a id="forward_60"></a>forward函数（上）：</h3> 
<h4><a id="_61"></a>模型初始化模块：</h4> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>opt<span class="token punctuation">,</span> paths<span class="token punctuation">,</span> gpu_ids<span class="token punctuation">,</span> refine_path<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#opt包含了试穿的相关参数，paths包含了用于加载模型的路径，gpu_ids指定了使用的GPU ID，refine_path指定了渲染的参考图片的路径。</span>
    cudnn<span class="token punctuation">.</span>enabled <span class="token operator">=</span> <span class="token boolean">True</span><span class="token comment">#启用cudnn并启用benchmark模式，以提高模型运行效率</span>
    cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">True</span><span class="token comment">#benchmark模式会根据输入数据的大小自动寻找最优算法来实现卷积、池化等操作，从而提高计算性能。</span>
    opt<span class="token punctuation">.</span>output_nc <span class="token operator">=</span> <span class="token number">3</span><span class="token comment">#输出图像通道数为3</span>

    gmm <span class="token operator">=</span> GMM<span class="token punctuation">(</span>opt<span class="token punctuation">)</span><span class="token comment">#创建一个GMM模型实例gmm</span>
    gmm <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>DataParallel<span class="token punctuation">(</span>gmm<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#torch.nn.DataParallel进行封装，使其可以并行地在多个GPU上运行</span>

    <span class="token comment"># 'batch'</span>
    <span class="token comment"># 初始化三个生成器模型，对应人体解析、虚拟试穿和面部优化三阶段</span>
    generator_parsing <span class="token operator">=</span> Define_G<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>input_nc_G_parsing<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>output_nc_parsing<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>ndf<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>netG_parsing<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>norm<span class="token punctuation">,</span> 
                            <span class="token keyword">not</span> opt<span class="token punctuation">.</span>no_dropout<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>init_type<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>init_gain<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>gpu_ids<span class="token punctuation">)</span>
    
    generator_app_cpvton <span class="token operator">=</span> Define_G<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>input_nc_G_app<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>output_nc_app<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>ndf<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>netG_app<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>norm<span class="token punctuation">,</span> 
                            <span class="token keyword">not</span> opt<span class="token punctuation">.</span>no_dropout<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>init_type<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>init_gain<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>gpu_ids<span class="token punctuation">,</span> with_tanh<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    
    generator_face <span class="token operator">=</span> Define_G<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>input_nc_D_face<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>output_nc_face<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>ndf<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>netG_face<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>norm<span class="token punctuation">,</span> 
                            <span class="token keyword">not</span> opt<span class="token punctuation">.</span>no_dropout<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>init_type<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>init_gain<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>gpu_ids<span class="token punctuation">)</span>

    models <span class="token operator">=</span> <span class="token punctuation">[</span>gmm<span class="token punctuation">,</span> generator_parsing<span class="token punctuation">,</span> generator_app_cpvton<span class="token punctuation">,</span> generator_face<span class="token punctuation">]</span><span class="token comment">#定义了一个列表 models，其中包含四个生成器模型。</span>
    <span class="token keyword">for</span> model<span class="token punctuation">,</span> path <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>models<span class="token punctuation">,</span> paths<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#通过迭代模型列表 models 中的每个模型以及对应的路径 paths，将模型参数加载到模型中。</span>
        load_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> path<span class="token punctuation">)</span><span class="token comment">#调用load_model函数来载入预训练模型的权重参数</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'==&gt;loaded model'</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="_87"></a>数据增强模块：</h4> 
<pre><code class="prism language-python">    augment <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token comment">#创建空的字典augment，存放数据增强的配置信息</span>

    <span class="token comment">#根据 PyTorch 版本选择不同的数据增强方式，数据增强（Data augmentation）是指在保持数据标签不变的前提下，对数据进行一定的变换，以增加数据量，提高模型的泛化能力。</span>
    <span class="token keyword">if</span> <span class="token string">'0.4'</span> <span class="token keyword">in</span> torch<span class="token punctuation">.</span>__version__<span class="token punctuation">:</span><span class="token comment">#如果 PyTorch 版本为 0.4，则将数据转换为一个三维张量，即 [C, H, W]，其中 C 表示图像的通道数，H 和 W 分别表示图像的高度和宽度。</span>
        <span class="token comment">#'3' 表示 RGB 彩色图像，'1' 表示单通道灰度图像</span>
        augment<span class="token punctuation">[</span><span class="token string">'3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
                                    <span class="token comment"># transforms.Resize(256),</span>
                                    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#将图像转换为 PyTorch 中的 tensor 类型，将像素值缩放到 [0, 1] 范围内，同时调整图像的通道顺序，变为 [C, H, W] 的形式。</span>
                                    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#对数据进行归一化操作，将图像的每个通道的像素值缩放到 [-1, 1] 范围内，其中第一个元组参数表示每个通道的均值，第二个元组参数表示每个通道的标准差。</span>
            <span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># change to [C, H, W]</span>
        augment<span class="token punctuation">[</span><span class="token string">'1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> augment<span class="token punctuation">[</span><span class="token string">'3'</span><span class="token punctuation">]</span><span class="token comment">#将 augment['1'] 设置为和 augment['3'] 相同的数据增强方式</span>

    <span class="token keyword">else</span><span class="token punctuation">:</span>
        augment<span class="token punctuation">[</span><span class="token string">'3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
                                <span class="token comment"># transforms.Resize(256),</span>
                                transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># change to [C, H, W]</span>

        augment<span class="token punctuation">[</span><span class="token string">'1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
                                <span class="token comment"># transforms.Resize(256),</span>
                                transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># change to [C, H, W]</span>
</code></pre> 
<h4><a id="_114"></a>数据初始化模块：</h4> 
<pre><code class="prism language-python">    val_dataset <span class="token operator">=</span> DemoDataset<span class="token punctuation">(</span>opt<span class="token punctuation">,</span> augment<span class="token operator">=</span>augment<span class="token punctuation">)</span><span class="token comment">#创建了一个 DemoDataset 对象 val_dataset，用于加载验证数据集</span>
    val_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span><span class="token comment">#创建了一个 DataLoader 对象 val_dataloader。dataLoader是PyTorch中用于加载和迭代数据的一个工具。它可以自动将数据集划分为batch，同时还可以实现数据的并行加载</span>
                    val_dataset<span class="token punctuation">,</span><span class="token comment">#从 val_dataset 中加载数据</span>
                    shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span><span class="token comment">#不打乱数据</span>
                    drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span><span class="token comment">#不丢弃数据集中不足一个 batch 的数据</span>
                    num_workers<span class="token operator">=</span>opt<span class="token punctuation">.</span>num_workers<span class="token punctuation">,</span><span class="token comment">#表示使用多少个线程加载数据</span>
                    batch_size <span class="token operator">=</span> opt<span class="token punctuation">.</span>batch_size_v<span class="token punctuation">,</span><span class="token comment">#将验证集的数据按照 batch_size_v 大小进行分批</span>
                    pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#将数据加载到 CUDA 固定内存中，以提高数据加载效率。</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e53640f7671bf984c2bb6320c717c041/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">LCD1602原理驱动代码及例程</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8d86b25ab6faa40cb882b356c587e4c6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">王道C语言督学营OJ练习全解【24考研最新版】</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 追风少年的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>