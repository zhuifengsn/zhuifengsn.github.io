<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>LLM æ¨¡å‹èåˆå®è·µæŒ‡å—ï¼šä½æˆæœ¬æ„å»ºé«˜æ€§èƒ½è¯­è¨€æ¨¡å‹ - è¿½é£å°‘å¹´çš„åšå®¢</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="LLM æ¨¡å‹èåˆå®è·µæŒ‡å—ï¼šä½æˆæœ¬æ„å»ºé«˜æ€§èƒ½è¯­è¨€æ¨¡å‹" />
<meta property="og:description" content="ç¼–è€…æŒ‰ï¼šéšç€å¤§è¯­è¨€æ¨¡å‹æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œæ¨¡å‹èåˆæˆä¸ºä¸€ç§ä½æˆæœ¬ä½†é«˜æ€§èƒ½çš„æ¨¡å‹æ„å»ºæ–°é€”å¾„ã€‚æœ¬æ–‡ä½œè€…Â Maxime LabonneÂ åˆ©ç”¨Â mergekitÂ åº“æ¢ç´¢äº†å››ç§æ¨¡å‹èåˆæ–¹æ³•ï¼šSLERPã€TIESã€DAREå’Œpassthroughã€‚é€šè¿‡é…ç½®ç¤ºä¾‹å’Œæ¡ˆä¾‹åˆ†æï¼Œä½œè€…è¯¦ç»†é˜é‡Šäº†è¿™äº›ç®—æ³•çš„åŸç†åŠå®è·µæ“ä½œã€‚
ä½œè€…çš„æ ¸å¿ƒè§‚ç‚¹æ˜¯ï¼šç›¸æ¯”è®­ç»ƒå…¨æ–°æ¨¡å‹ï¼Œèåˆç°æœ‰æ¨¡å‹å¯ä»¥ä»¥æ›´ä½è®¡ç®—æˆæœ¬è·å–ç±»ä¼¼æˆ–æ›´ä¼˜å¼‚çš„æ•ˆæœã€‚
æ–‡ç« é€šè¿‡æ¨¡å‹èåˆç”Ÿæˆäº†æ€§èƒ½ä¼˜å¼‚çš„Â Marcoro14-7B-slerpÂ ã€‚åœ¨Â Open LLM LeaderboardÂ å’ŒÂ NousResearchÂ ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸Šï¼Œå®ƒéƒ½æ˜¯åŒå‚æ•°é‡æ¨¡å‹ä¸­çš„ä½¼ä½¼è€…ã€‚æ¡ˆä¾‹éªŒè¯äº†ä½œè€…ä¸»å¼ çš„æ¨¡å‹èåˆå­˜åœ¨çš„é«˜æ€§ä»·æ¯”ã€‚å½“ç„¶æ¨¡å‹èåˆä¹Ÿå­˜åœ¨ä¸€å®šé—®é¢˜ï¼Œå¦‚è®­ç»ƒæ•°æ®æ±¡æŸ“å’Œå¯èƒ½åœ¨å„ç§è¯„æµ‹æ’è¡Œæ¦œçš„åˆ†æ•°åé«˜ã€‚æœ¬æ–‡æä¾›äº†æ¨¡å‹èåˆæŠ€æœ¯ä¸å·¥ç¨‹å®è·µçš„è¯¦å°½æŒ‡å—ï¼Œå¯¹AIå®è·µè€…å…·æœ‰é‡è¦å‚è€ƒä»·å€¼ã€‚
ä½œè€… | Maxime Labonne
ç¼–è¯‘Â |Â å²³æ‰¬
Image by author
æ¨¡å‹èåˆï¼ˆModel mergingï¼‰æ˜¯ä¸€ç§å°†ä¸¤ä¸ªæˆ–æ›´å¤šä¸ªå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åˆå¹¶ä¸ºä¸€ä¸ªæ¨¡å‹çš„æŠ€æœ¯ã€‚è¿™æ˜¯ä¸€ç§ç›¸å¯¹è¾ƒæ–°çš„å®éªŒæ€§æ–¹æ³•ï¼Œå¯ä»¥ä»¥è¾ƒä½æˆæœ¬ï¼ˆæ— éœ€Â GPUï¼‰åˆ›å»ºæ–°æ¨¡å‹ã€‚ ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œè¿™ç§æŠ€æœ¯çš„æ•ˆæœè¿˜æ¯”è¾ƒå‡ºå¥‡ï¼Œä½¿ç”¨æ¨¡å‹èåˆæŠ€æœ¯åœ¨Â Open LLMÂ Leaderboard[1]ä¸Šäº§ç”Ÿäº†è®¸å¤šæœ€å…ˆè¿›çš„æ¨¡å‹ã€‚
åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Â mergekitÂ [2]åº“æ¥å®ç°è¿™ä¸€æŠ€æœ¯ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬å°†å›é¡¾å››ç§æ¨¡å‹èåˆæ–¹æ³•ï¼Œå¹¶æä¾›ç›¸å…³çš„é…ç½®ç¤ºä¾‹ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Â mergekitÂ åˆ›å»ºä¸€ä¸ªæ¨¡å‹ï¼šMarcoro14â€“7B-slerp[3]ï¼Œè¯¥æ¨¡å‹å·²æˆä¸ºÂ Open LLMÂ Leaderboardï¼ˆ02/01/24ï¼‰ä¸Šè¡¨ç°æœ€ä½³çš„æ¨¡å‹ã€‚
ç›¸å…³ä»£ç å·²ä¸Šä¼ è‡³Â GitHub[4]Â å’ŒÂ Notebook[5]ã€‚ä¸ªäººå»ºè®®ä½¿ç”¨Â LazyMergekit[6]Â é¡¹ç›®ï¼Œæ¥è½»æ¾è¿è¡ŒÂ mergekitã€‚
ç‰¹åˆ«æ„Ÿè°¢Â mergekitÂ åº“çš„ä½œè€…Â Charles Goddard[7]Â å®¡é˜…æœ¬æ–‡ã€‚
Image by author
01 ğŸ¤Â èåˆç®—æ³• åœ¨æœ¬èŠ‚ï¼Œæˆ‘ä»¬å°†é‡ç‚¹ä»‹ç»Â mergekitÂ åº“ç›®å‰å®ç°çš„å››ç§æ¨¡å‹èåˆæ–¹æ³•ã€‚è¯·æ³¨æ„ï¼Œè¿˜æœ‰å…¶ä»–æ–¹æ³•ï¼Œæ¯”å¦‚Â linearÂ [8]å’ŒÂ Task ArithmeticÂ [9]ã€‚å¦‚æœä½ å¯¹æ¨¡å‹èåˆçš„ç›¸å…³è®ºæ–‡æ„Ÿå…´è¶£ï¼Œæˆ‘æ¨èé˜…è¯»Hugging Faceä¸Šçš„è¿™æœ¬ä¼˜ç§€è®ºæ–‡é›†[10]ã€‚" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zhuifengsn.github.io/posts/fce15fb3313d95ce4cb588006248a106/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-02-21T10:17:03+08:00" />
<meta property="article:modified_time" content="2024-02-21T10:17:03+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="è¿½é£å°‘å¹´çš„åšå®¢" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">è¿½é£å°‘å¹´çš„åšå®¢</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">LLM æ¨¡å‹èåˆå®è·µæŒ‡å—ï¼šä½æˆæœ¬æ„å»ºé«˜æ€§èƒ½è¯­è¨€æ¨¡å‹</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p><strong>ç¼–è€…æŒ‰</strong>ï¼šéšç€å¤§è¯­è¨€æ¨¡å‹æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œæ¨¡å‹èåˆæˆä¸ºä¸€ç§ä½æˆæœ¬ä½†é«˜æ€§èƒ½çš„æ¨¡å‹æ„å»ºæ–°é€”å¾„ã€‚æœ¬æ–‡ä½œè€…Â Maxime LabonneÂ åˆ©ç”¨Â mergekitÂ åº“æ¢ç´¢äº†å››ç§æ¨¡å‹èåˆæ–¹æ³•ï¼šSLERPã€TIESã€DAREå’Œpassthroughã€‚é€šè¿‡é…ç½®ç¤ºä¾‹å’Œæ¡ˆä¾‹åˆ†æï¼Œä½œè€…è¯¦ç»†é˜é‡Šäº†è¿™äº›ç®—æ³•çš„åŸç†åŠå®è·µæ“ä½œã€‚</p> 
 <p>ä½œè€…çš„æ ¸å¿ƒè§‚ç‚¹æ˜¯ï¼š<strong>ç›¸æ¯”è®­ç»ƒå…¨æ–°æ¨¡å‹ï¼Œèåˆç°æœ‰æ¨¡å‹å¯ä»¥ä»¥æ›´ä½è®¡ç®—æˆæœ¬è·å–ç±»ä¼¼æˆ–æ›´ä¼˜å¼‚çš„æ•ˆæœã€‚</strong></p> 
 <p>æ–‡ç« é€šè¿‡æ¨¡å‹èåˆç”Ÿæˆäº†æ€§èƒ½ä¼˜å¼‚çš„Â Marcoro14-7B-slerpÂ ã€‚åœ¨Â Open LLM LeaderboardÂ å’ŒÂ NousResearchÂ ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸Šï¼Œå®ƒéƒ½æ˜¯åŒå‚æ•°é‡æ¨¡å‹ä¸­çš„ä½¼ä½¼è€…ã€‚æ¡ˆä¾‹éªŒè¯äº†ä½œè€…ä¸»å¼ çš„æ¨¡å‹èåˆå­˜åœ¨çš„é«˜æ€§ä»·æ¯”ã€‚å½“ç„¶æ¨¡å‹èåˆä¹Ÿå­˜åœ¨ä¸€å®šé—®é¢˜ï¼Œå¦‚è®­ç»ƒæ•°æ®æ±¡æŸ“å’Œå¯èƒ½åœ¨å„ç§è¯„æµ‹æ’è¡Œæ¦œçš„åˆ†æ•°åé«˜ã€‚æœ¬æ–‡æä¾›äº†æ¨¡å‹èåˆæŠ€æœ¯ä¸å·¥ç¨‹å®è·µçš„è¯¦å°½æŒ‡å—ï¼Œå¯¹AIå®è·µè€…å…·æœ‰é‡è¦å‚è€ƒä»·å€¼ã€‚</p> 
</blockquote> 
<p><strong>ä½œè€… | Maxime Labonne</strong></p> 
<p><strong>ç¼–è¯‘Â |Â å²³æ‰¬</strong></p> 
<p><img src="https://images2.imgbox.com/a4/8e/rHFGvWa1_o.png" alt=""></p> 
<p>Image by author</p> 
<p>æ¨¡å‹èåˆï¼ˆModel mergingï¼‰æ˜¯ä¸€ç§å°†ä¸¤ä¸ªæˆ–æ›´å¤šä¸ªå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åˆå¹¶ä¸ºä¸€ä¸ªæ¨¡å‹çš„æŠ€æœ¯ã€‚<strong>è¿™æ˜¯ä¸€ç§ç›¸å¯¹è¾ƒæ–°çš„å®éªŒæ€§æ–¹æ³•ï¼Œå¯ä»¥ä»¥è¾ƒä½æˆæœ¬ï¼ˆæ— éœ€Â GPUï¼‰åˆ›å»ºæ–°æ¨¡å‹ã€‚</strong> ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œè¿™ç§æŠ€æœ¯çš„æ•ˆæœè¿˜æ¯”è¾ƒå‡ºå¥‡ï¼Œä½¿ç”¨æ¨¡å‹èåˆæŠ€æœ¯åœ¨Â Open LLMÂ Leaderboard[1]ä¸Šäº§ç”Ÿäº†è®¸å¤šæœ€å…ˆè¿›çš„æ¨¡å‹ã€‚</p> 
<p>åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Â mergekitÂ [2]åº“æ¥å®ç°è¿™ä¸€æŠ€æœ¯ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬å°†å›é¡¾å››ç§æ¨¡å‹èåˆæ–¹æ³•ï¼Œå¹¶æä¾›ç›¸å…³çš„é…ç½®ç¤ºä¾‹ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Â mergekitÂ åˆ›å»ºä¸€ä¸ªæ¨¡å‹ï¼šMarcoro14â€“7B-slerp[3]ï¼Œè¯¥æ¨¡å‹å·²æˆä¸ºÂ Open LLMÂ Leaderboardï¼ˆ02/01/24ï¼‰ä¸Šè¡¨ç°æœ€ä½³çš„æ¨¡å‹ã€‚</p> 
<p>ç›¸å…³ä»£ç å·²ä¸Šä¼ è‡³Â GitHub[4]Â å’ŒÂ Notebook[5]ã€‚ä¸ªäººå»ºè®®ä½¿ç”¨Â LazyMergekit[6]Â é¡¹ç›®ï¼Œæ¥è½»æ¾è¿è¡ŒÂ mergekitã€‚</p> 
<p>ç‰¹åˆ«æ„Ÿè°¢Â mergekitÂ åº“çš„ä½œè€…Â Charles Goddard[7]Â å®¡é˜…æœ¬æ–‡ã€‚</p> 
<p><img src="https://images2.imgbox.com/84/57/M3ZkDPA2_o.png" alt=""></p> 
<p>Image by author</p> 
<h2><a id="01_%C2%A0_30"></a><strong>01 ğŸ¤Â èåˆç®—æ³•</strong></h2> 
<p>åœ¨æœ¬èŠ‚ï¼Œæˆ‘ä»¬å°†é‡ç‚¹ä»‹ç»Â mergekitÂ åº“ç›®å‰å®ç°çš„å››ç§æ¨¡å‹èåˆæ–¹æ³•ã€‚è¯·æ³¨æ„ï¼Œè¿˜æœ‰å…¶ä»–æ–¹æ³•ï¼Œæ¯”å¦‚Â linearÂ [8]å’ŒÂ Task ArithmeticÂ [9]ã€‚å¦‚æœä½ å¯¹æ¨¡å‹èåˆçš„ç›¸å…³è®ºæ–‡æ„Ÿå…´è¶£ï¼Œæˆ‘æ¨èé˜…è¯»Hugging Faceä¸Šçš„è¿™æœ¬ä¼˜ç§€è®ºæ–‡é›†[10]ã€‚</p> 
<h3><a id="11_SLERP_34"></a><strong>1.1 SLERP</strong></h3> 
<p>Spherical Linear Interpolationï¼ˆSLERPï¼‰æ˜¯ä¸€ç§ç”¨äºåœ¨ä¸¤ä¸ªå‘é‡ä¹‹é—´è¿›è¡Œå¹³ç¨³å’Œè¿è´¯åœ°æ’å€¼çš„æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿä¿æŒæ’å®šçš„å˜åŒ–é€Ÿç‡ï¼Œå¹¶ä¿ç•™å‘é‡æ‰€åœ¨çƒé¢ç©ºé—´çš„å‡ ä½•ç‰¹æ€§ã€‚</p> 
<p>ä¸ä½¿ç”¨ä¼ ç»Ÿçš„çº¿æ€§æ’å€¼æ–¹æ³•ç›¸æ¯”ï¼ŒSLERPÂ æ›´å—é’ççš„åŸå› æœ‰å‡ ä¸ªã€‚ä¾‹å¦‚ï¼Œåœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œçº¿æ€§æ’å€¼ï¼ˆlinear interpolationï¼‰å¯èƒ½å¯¼è‡´æ’å€¼å‘é‡çš„å¤§å°ï¼ˆå¹…åº¦ï¼‰å‡å°ï¼ˆå³æƒé‡çš„è§„æ¨¡å‡å°ï¼‰ã€‚æ­¤å¤–ï¼Œ<strong>æƒé‡æ–¹å‘çš„å˜åŒ–å¾€å¾€æ¯”å¤§å°ï¼ˆå¹…åº¦ï¼‰çš„å˜åŒ–ä»£è¡¨çš„ä¿¡æ¯æ›´æœ‰æ„ä¹‰</strong>ï¼ˆå¦‚ç‰¹å¾å­¦ä¹ ï¼ˆFeature Learningï¼‰å’Œè¡¨å¾ï¼ˆRepresentationï¼‰ï¼‰ã€‚</p> 
<p>SLERPÂ æ˜¯é€šè¿‡ä»¥ä¸‹æ­¥éª¤å®ç°çš„ï¼š</p> 
<ol><li>å¯¹è¾“å…¥çš„å‘é‡è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼Œä½¿å®ƒä»¬çš„é•¿åº¦ï¼ˆmagnitudeï¼‰å˜ä¸ºå•ä½é•¿åº¦ï¼ˆé•¿åº¦ä¸º1ï¼‰ã€‚è¿™ä¸€æ­¥éª¤çš„ç›®çš„æ˜¯ç¡®ä¿è¿™äº›å‘é‡è¡¨ç¤ºçš„æ˜¯æ–¹å‘ï¼Œè€Œä¸æ˜¯å¤§å°ã€‚</li><li>ä½¿ç”¨ç‚¹ç§¯è®¡ç®—è¿™äº›å‘é‡ä¹‹é—´çš„è§’åº¦ã€‚</li><li>å¦‚æœè¿™äº›å‘é‡å‡ ä¹å¹³è¡Œï¼Œåˆ™é»˜è®¤ä½¿ç”¨çº¿æ€§æ’å€¼ä»¥æé«˜æ•ˆç‡ã€‚å¦‚æœè¾“å…¥çš„ä¸¤ä¸ªå‘é‡å¤¹è§’è¾ƒå¤§ï¼ŒSLERPÂ å°†æ ¹æ®æ’å€¼å› å­Â tÂ ï¼ˆ<strong>æ’å€¼å› å­Â tÂ æ˜¯ä¸€ä¸ªä»‹äºÂ 0Â åˆ°Â 1Â ä¹‹é—´çš„å€¼ï¼Œç”¨äºæŒ‡å®šæ’å€¼çš„ç¨‹åº¦ã€‚t=0Â è¡¨ç¤ºå®Œå…¨ä½¿ç”¨ç¬¬ä¸€ä¸ªå‘é‡ï¼Œt=1Â è¡¨ç¤ºå®Œå…¨ä½¿ç”¨ç¬¬äºŒä¸ªå‘é‡ï¼Œè€Œåœ¨Â 0Â åˆ°Â 1Â ä¹‹é—´çš„å€¼è¡¨ç¤ºä¸¤ä¸ªå‘é‡çš„æ··åˆç¨‹åº¦ã€‚</strong> ï¼‰å’Œå‘é‡ä¹‹é—´çš„å¤¹è§’è®¡ç®—æ¯”ä¾‹å› å­ï¼ˆScale factorï¼‰ã€‚</li><li>è¿™äº›å› å­ç”¨äºç»™åŸå§‹å‘é‡åŠ æƒï¼Œç„¶åæ±‚å’Œæ¥è·å¾—æ’å€¼å‘é‡ã€‚</li></ol> 
<p>SLERPÂ ç›®å‰æ˜¯æœ€æµè¡Œçš„æ¨¡å‹èåˆæ–¹æ³•ï¼Œä½†å®ƒä»…é™äºä¸€æ¬¡åˆå¹¶ä¸¤ä¸ªæ¨¡å‹ã€‚ä¸è¿‡ï¼Œä»ç„¶å¯ä»¥é€šè¿‡åˆ†å±‚èåˆå¤šä¸ªæ¨¡å‹ï¼Œå°±åƒåœ¨Â Mistral-7B-Merge-14-v0.1[11]Â ä¸­æ‰€ç¤ºã€‚</p> 
<p><strong>é…ç½®ç¤ºä¾‹ï¼š</strong></p> 
<pre><code>slices:
Â Â -Â sources:
Â Â Â Â Â Â -Â model:Â OpenPipe/mistral-ft-optimized-1218
Â Â Â Â Â Â Â Â layer_range:Â [0,Â 32]
Â Â Â Â Â Â -Â model:Â mlabonne/NeuralHermes-2.5-Mistral-7B
Â Â Â Â Â Â Â Â layer_range:Â [0,Â 32]
merge_method:Â slerp
base_model:Â OpenPipe/mistral-ft-optimized-1218
parameters:
Â Â t:
Â Â Â Â -Â filter:Â self_attn
Â Â Â Â Â Â value:Â [0,Â 0.5,Â 0.3,Â 0.7,Â 1]
Â Â Â Â -Â filter:Â mlp
Â Â Â Â Â Â value:Â [1,Â 0.5,Â 0.7,Â 0.3,Â 0]
Â Â Â Â -Â value:Â 0.5
dtype:Â bfloat16
</code></pre> 
<p>è¿™æ˜¯ä¸€ç§ç»å…¸çš„Â SLERPÂ é…ç½®ï¼ŒSLERPÂ è¢«åº”ç”¨äºæ¨¡å‹çš„æ¯ä¸€å±‚ï¼Œä»¥å®Œæˆæ•´ä½“çš„æ¨¡å‹èåˆã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä¸ºæ’å€¼å› å­Â tÂ è¾“å…¥äº†ä¸€ç³»åˆ—æ¢¯åº¦å€¼ï¼ˆgradient of valuesï¼‰ã€‚è‡ªæ³¨æ„åŠ›å±‚å’ŒÂ MLPÂ å±‚çš„å‚æ•°å°†ä½¿ç”¨Â OpenPipe/mistral-ft-optimized-1218[12]Â å’ŒÂ mlabonne/NeuralHermes-2.5-Mistral-7B[13]Â çš„ä¸åŒç»„åˆã€‚</p> 
<p>å¯ä»¥åœ¨Â Hugging Face HubÂ ä¸Šæ‰¾åˆ°æœ€ç»ˆè®­ç»ƒå®Œæˆçš„æ¨¡å‹ï¼Œä½äºÂ mlabonne/NeuralPipe-7B-slerp[14]ã€‚</p> 
<h3><a id="12_TIES_74"></a><strong>1.2 TIES</strong></h3> 
<p>TIES-MergingÂ ç”±Â YadavÂ ç­‰äººåœ¨è¿™ç¯‡è®ºæ–‡[15]ä¸­å¼•å…¥ï¼ŒTIES-MergingÂ æ—¨åœ¨å°†å¤šä¸ªç‰¹å®šä»»åŠ¡æ¨¡å‹é«˜æ•ˆåœ°åˆå¹¶ä¸ºä¸€ä¸ªå¤šä»»åŠ¡æ¨¡å‹ã€‚å®ƒè§£å†³äº†æ¨¡å‹èåˆä¸­çš„ä¸¤å¤§éš¾é¢˜ï¼š</p> 
<ul><li><strong>æ¨¡å‹å‚æ•°çš„å†—ä½™</strong>ï¼šå®ƒèƒ½å¤Ÿè¯†åˆ«å¹¶æ¶ˆé™¤ç‰¹å®šä»»åŠ¡æ¨¡å‹ä¸­çš„å†—ä½™å‚æ•°ã€‚å…·ä½“åšæ³•æ˜¯åœ¨æ¨¡å‹å¾®è°ƒï¼ˆfine-tuningï¼‰çš„è¿‡ç¨‹ä¸­ï¼Œå…³æ³¨æ¨¡å‹å‚æ•°å‘ç”Ÿçš„å˜åŒ–ï¼Œå¯¹å¾®è°ƒè¿‡ç¨‹ä¸­å‘ç”Ÿçš„å˜åŒ–è¿›è¡Œæ’åºï¼Œå¹¶é€‰æ‹©é‚£äº›å¯¹æ¨¡å‹æ€§èƒ½å½±å“æœ€æ˜¾è‘—çš„å‰Â k%Â çš„å˜åŒ–ï¼Œå¹¶å¿½ç•¥é‚£äº›åœ¨å¾®è°ƒä¸­å˜åŒ–è¾ƒå°æˆ–å¯¹æ€§èƒ½å½±å“è¾ƒå°çš„éƒ¨åˆ†ã€‚</li><li><strong>æ¨¡å‹å‚æ•°çš„ç¬¦å·ä¹‹é—´å­˜åœ¨åˆ†æ­§</strong>ï¼šå½“ä¸åŒæ¨¡å‹å¯¹åŒä¸€å‚æ•°æå‡ºç›¸åçš„è°ƒæ•´å»ºè®®æ—¶ï¼Œå°±ä¼šäº§ç”Ÿå†²çªã€‚TIES-MergingÂ é€šè¿‡åˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„ç¬¦å·å‘é‡æ¥è§£å†³è¿™äº›å†²çªï¼Œè¯¥å‘é‡è¡¨ç¤ºæ‰€æœ‰æ¨¡å‹ä¸­å˜åŒ–æ–¹å‘çš„æœ€æ˜¾è‘—æ–¹å‘ã€‚</li></ul> 
<p>TIES-MergingÂ åˆ†ä¸ºä»¥ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š</p> 
<ul><li><strong>Trimï¼ˆä¿®å‰ªï¼‰</strong> ï¼šåªä¿ç•™ä¸€éƒ¨åˆ†æœ€é‡è¦çš„å‚æ•°ï¼ˆå¯†åº¦å‚æ•°ï¼ˆdensity parameterï¼‰ï¼‰ï¼Œå¹¶å°†å…¶ä½™å‚æ•°é‡ç½®ä¸ºé›¶ï¼Œä»è€Œå‡å°‘ç‰¹å®šä»»åŠ¡æ¨¡å‹ä¸­çš„å†—ä½™å‚æ•°ã€‚</li><li><strong>Elect Signï¼ˆç¡®å®šç¬¦å·ï¼‰</strong> ï¼šé€šè¿‡ç¡®å®šæ¨¡å‹ä¸­å“ªäº›æ–¹å‘ä¸Šçš„å˜åŒ–ï¼ˆæ­£å‘æˆ–è´Ÿå‘ï¼‰æ˜¯æœ€ä¸ºæ˜¾è‘—æˆ–æœ€ä¸»å¯¼çš„ï¼Œåˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„ç¬¦å·å‘é‡ï¼Œä»¥è§£å†³ä¸åŒæ¨¡å‹ä¹‹é—´çš„ç¬¦å·å†²çªã€‚</li><li><strong>Disjoint Merge</strong>ï¼šåœ¨åˆå¹¶è¿‡ç¨‹ä¸­ï¼Œä»…è€ƒè™‘é‚£äº›ä¸å…ˆå‰åˆ›å»ºçš„ç»Ÿä¸€ç¬¦å·å‘é‡ä¸€è‡´çš„å‚æ•°å€¼ï¼Œå¹¶è®¡ç®—è¿™äº›å€¼çš„å¹³å‡å€¼ã€‚åœ¨è®¡ç®—å¹³å‡å€¼æ—¶ï¼Œä¸è€ƒè™‘åŸå§‹å‚æ•°å€¼ä¸ºé›¶çš„æƒ…å†µã€‚</li></ul> 
<p>ä¸Â SLERPÂ ä¸åŒï¼ŒTIESÂ å¯ä»¥ä¸€æ¬¡æ€§åˆå¹¶å¤šä¸ªæ¨¡å‹ã€‚</p> 
<p><strong>é…ç½®ç¤ºä¾‹ï¼š</strong></p> 
<pre><code>models:
Â Â -Â model:Â mistralai/Mistral-7B-v0.1
Â Â Â Â #Â no parameters necessary for base model
Â Â -Â model:Â OpenPipe/mistral-ft-optimized-1218
Â Â Â Â parameters:
Â Â Â Â Â Â density:Â 0.5
Â Â Â Â Â Â weight:Â 0.5
Â Â -Â model:Â mlabonne/NeuralHermes-2.5-Mistral-7B
Â Â Â Â parameters:
Â Â Â Â Â Â density:Â 0.5
Â Â Â Â Â Â weight:Â 0.3
merge_method:Â ties
base_model:Â mistralai/Mistral-7B-v0.1
parameters:
Â Â normalize:Â true
dtype:Â float16
</code></pre> 
<p>åœ¨æ­¤é…ç½®ä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨Â Mistral-7BÂ ä½œä¸ºåŸºç¡€æ¨¡å‹æ¥è®¡ç®—Â deltaÂ æƒé‡ã€‚æˆ‘ä»¬èåˆäº†ä¸¤ä¸ªæ¨¡å‹ï¼šmistral-ft-optimized-1218ï¼ˆ50%ï¼‰[12]å’ŒÂ NeuralHermes-2.5-Mistral-7Bï¼ˆ30%ï¼‰[13]ï¼Œå¹¶è¿›è¡Œäº†å½’ä¸€åŒ–å¤„ç†ã€‚è¿™é‡Œçš„â€œdensityâ€å‚æ•°æ„å‘³ç€æˆ‘ä»¬åªä¿ç•™äº†æ¯ä¸ªæ¨¡å‹Â 50%çš„å‚æ•°ï¼ˆå¦ä¸€åŠæ¥è‡ªåŸºç¡€æ¨¡å‹ï¼‰ã€‚</p> 
<p><strong>è¯·æ³¨æ„ï¼Œåœ¨é…ç½®ä¸­æƒé‡ä¹‹å’Œä¸ç­‰äºÂ 1ï¼Œä½†Â normalize:Â trueÂ å‚æ•°ä¼šè‡ªåŠ¨åœ¨å†…éƒ¨å°†å…¶å½’ä¸€åŒ–ã€‚</strong> æ­¤é…ç½®çš„çµæ„Ÿæ¥è‡ªÂ OpenHermes-2.5-neural-chat-7b-v3-1-7B[16]Â è¿™ä¸ªæ¨¡å‹çš„ä½œè€…æä¾›çš„å‚æ•°ã€‚</p> 
<p>ä½ å¯ä»¥åœ¨Â Hugging Face HubÂ ä¸Šçš„Â mlabonne/NeuralPipe-7B-ties[17]Â æ‰¾åˆ°æœ€ç»ˆè®­ç»ƒå®Œæˆçš„æ¨¡å‹ã€‚</p> 
<h3><a id="13_DARE_116"></a><strong>1.3 DARE</strong></h3> 
<p>DARE[18]Â ç”±Â YuÂ ç­‰äººï¼ˆ2023Â å¹´ï¼‰æå‡ºï¼Œä½¿ç”¨äº†ä¸Â TIESÂ ç±»ä¼¼çš„æ–¹æ³•ï¼Œä½†æœ‰ä¸¤ä¸ªä¸»è¦åŒºåˆ«ï¼š</p> 
<ul><li><strong>Pruning</strong>ï¼šÂ DAREÂ éšæœºå°†å¾®è°ƒåçš„æƒé‡é‡ç½®ä¸ºåŸå§‹å€¼ï¼ˆåŸºç¡€æ¨¡å‹çš„æƒé‡ï¼‰ã€‚</li><li><strong>Rescaling</strong>ï¼šÂ DAREÂ é‡æ–°è°ƒæ•´æƒé‡ï¼Œä»¥ä¿æŒæ¨¡å‹è¾“å‡ºçš„æœŸæœ›å€¼å¤§è‡´ä¸å˜ã€‚å®ƒå°†ä¸¤ä¸ªï¼ˆæˆ–æ›´å¤šï¼‰æ¨¡å‹çš„é‡è°ƒæ•´åçš„æƒé‡ä¸åŸºç¡€æ¨¡å‹çš„æƒé‡ç›¸åŠ ï¼Œå¹¶ä½¿ç”¨äº†ä¸€ä¸ªæ¯”ä¾‹å› å­ã€‚</li></ul> 
<p>MergekitÂ å¯¹è¿™ç§æ–¹æ³•çš„å®ç°æœ‰ä¸¤ç§ï¼šæœ‰Â TIESÂ çš„ç¡®å®šç¬¦å·æ­¥éª¤ï¼ˆdare_tiesï¼‰æˆ–æ²¡æœ‰Â TIESÂ çš„ç¡®å®šç¬¦å·æ­¥éª¤ï¼ˆdare_linearï¼‰ã€‚</p> 
<p><strong>é…ç½®ç¤ºä¾‹ï¼š</strong></p> 
<pre><code>models:
 - model:Â mistralai/Mistral-7B-v0.1
 #Â No parameters necessary for base model
 - model:Â samir-fama/SamirGPT-v1
 parameters:
 density: 0.53
 weight: 0.4
 - model:Â abacusai/Slerp-CM-mist-dpo
 parameters:
 density: 0.53
 weight: 0.3
 - model:Â EmbeddedLLM/Mistral-7B-Merge-14-v0.2
 parameters:
 density: 0.53
 weight: 0.3
merge_method:Â dare_ties
base_model:Â mistralai/Mistral-7B-v0.1
parameters:
 int8_mask: true
dtype:Â bfloat16
</code></pre> 
<p>åœ¨è¿™ä¸ªé…ç½®ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨Â dare_tiesÂ åˆå¹¶äº†åŸºäºÂ Mistral-7BÂ çš„ä¸‰ä¸ªä¸åŒæ¨¡å‹ã€‚è¿™æ¬¡ï¼Œæˆ‘é€‰æ‹©çš„æƒé‡æ€»å’Œä¸ºÂ 1ï¼ˆæ€»å’Œåº”åœ¨Â 0.9Â å’ŒÂ 1.1Â ä¹‹é—´ï¼‰ã€‚densityÂ å‚æ•°ç•¥é«˜äºè®ºæ–‡ä¸­å»ºè®®çš„å€¼ï¼ˆ&lt;0.5ï¼‰ï¼Œä½†çœ‹èµ·æ¥å®ƒèƒ½æŒç»­æä¾›æ›´å¥½çš„ç»“æœï¼ˆå‚è§æ­¤è®¨è®º[19]ï¼‰ã€‚</p> 
<p>ä½ å¯ä»¥åœ¨Â Hugging Face HubÂ çš„Â mlabonne/Daredevil-7B[20]Â ä¸Šæ‰¾åˆ°å®ƒã€‚å®ƒä¹Ÿæ˜¯æœ¬æ–‡ä¸­æœ€å¥½çš„åˆå¹¶æ¨¡å‹ï¼Œç”šè‡³ä¼˜äºÂ Marcoro14-7B-slerpã€‚</p> 
<h3><a id="14_Passthrough_154"></a><strong>1.4 Passthrough</strong></h3> 
<p>PassthroughÂ æ–¹æ³•ä¸å‰å‡ ç§æ–¹æ³•æœ‰å¾ˆå¤§ä¸åŒã€‚<strong>é€šè¿‡è¿æ¥æ¥è‡ªä¸åŒÂ LLMsÂ çš„æ¨¡å‹å±‚ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥ç”Ÿæˆå…·æœ‰å¥‡æ€ªå‚æ•°æ•°é‡çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨ä¸¤ä¸ªÂ 7BÂ å‚æ•°æ¨¡å‹å¯ä»¥ç”ŸæˆÂ 9BÂ æ¨¡å‹ï¼‰ã€‚</strong> è¿™äº›æ¨¡å‹é€šå¸¸è¢«ç§°ä¸ºÂ "FrankenmergesÂ "æˆ–Â â€œFrankensteinÂ æ¨¡å‹â€ã€‚</p> 
<p>è¿™ç§æŠ€æœ¯æå…·å®éªŒæ€§ï¼Œä½†èƒ½å¤ŸæˆåŠŸåœ°åˆ›å»ºä¸€äº›ä»¤äººå°è±¡æ·±åˆ»çš„æ¨¡å‹ï¼Œæ¯”å¦‚ä½¿ç”¨ä¸¤ä¸ªÂ Llama 2 70BÂ æ¨¡å‹èåˆè€Œæˆçš„Â goliath-120bã€‚æœ€è¿‘å‘å¸ƒçš„Â SOLAR-10.7B-v1.0Â ä¹Ÿä½¿ç”¨äº†åŒæ ·çš„æ€æƒ³ï¼Œåœ¨ä»–ä»¬çš„è®ºæ–‡ä¸­è¿™ç§æŠ€æœ¯ç§°ä¸º"depth-up scaling"ã€‚</p> 
<p><strong>é…ç½®ç¤ºä¾‹ï¼š</strong></p> 
<pre><code>slices:
Â Â -Â sources:
Â Â Â Â -Â model:Â OpenPipe/mistral-ft-optimized-1218
Â Â Â Â Â Â layer_range:Â [0,Â 32]
Â Â -Â sources:
Â Â Â Â -Â model:Â mlabonne/NeuralHermes-2.5-Mistral-7B
Â Â Â Â Â Â layer_range:Â [24,Â 32]
merge_method:Â passthrough
dtype:Â bfloat16
</code></pre> 
<p>ç”±æ­¤äº§ç”Ÿçš„Â frankenmergeÂ æ¨¡å‹å°†åŒ…å«ç¬¬ä¸€ä¸ªæ¨¡å‹çš„å…¨éƒ¨Â 32Â å±‚å’Œç¬¬äºŒä¸ªæ¨¡å‹çš„Â 8Â ä¸ªé™„åŠ å±‚ã€‚è¿™å°†åˆ›å»ºä¸€ä¸ªæ€»å…±æœ‰Â 40Â å±‚å’ŒÂ 8.99BÂ å‚æ•°çš„Â frankenmergeã€‚æ­¤é…ç½®çš„çµæ„Ÿæ¥è‡ªäºÂ GML-Mistral-merged-v1[21]ã€‚</p> 
<p>æ‚¨å¯ä»¥åœ¨Â Hugging Face HubÂ ä¸Šçš„Â mlabonne/NeuralPipe-9B-mergedÂ [22]æ‰¾åˆ°æœ€ç»ˆæ¨¡å‹ã€‚</p> 
<h2><a id="02_%C2%A0_178"></a><strong>02 ğŸ’»Â èåˆæˆ‘ä»¬è‡ªå·±çš„æ¨¡å‹</strong></h2> 
<p>åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Â mergekitÂ åº“åŠ è½½ä¸€ä¸ªæ¨¡å‹èåˆé…ç½®ï¼Œè¿è¡Œå®ƒå¹¶å°†ç”Ÿæˆçš„ç»“æœæ¨¡å‹ä¸Šä¼ åˆ°Â Hugging Face Hubã€‚</p> 
<p>é¦–å…ˆï¼Œæˆ‘ä»¬ç›´æ¥é€šè¿‡æºä»£ç å®‰è£…Â mergekitï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š</p> 
<pre><code>!git clone https://github.com/cg123/mergekit.git
!cd mergekitÂ &amp;&amp;Â pip installÂ -qÂ -eÂ .
</code></pre> 
<p>åœ¨ä¸‹é¢çš„ä»£ç å—ä¸­ï¼Œæˆ‘ä»¬å°†ä»¥Â YAMLÂ æ ¼å¼åŠ è½½æ¨¡å‹èåˆé…ç½®ã€‚è¿˜åœ¨æ­¤æŒ‡å®šäº†å®Œæˆæ¨¡å‹èåˆåæ¨¡å‹çš„åç§°ï¼Œä»¥å¤‡å°†æ¥ä½¿ç”¨ã€‚æ‚¨å¯ä»¥åœ¨æ­¤å¤åˆ¶/ç²˜è´´ä¸Šä¸€èŠ‚ä¸­çš„ä»»ä½•é…ç½®ã€‚</p> 
<p>è¿™æ¬¡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸¤ä¸ªä¸åŒçš„æ¨¡å‹ï¼šÂ Marcoroni-7B-v3[23]Â å’ŒÂ Mistral-7B-Merge-14-v0.1[24]Â å¹¶ç”¨Â SLERPÂ æ–¹æ³•è¿›è¡Œæ¨¡å‹èåˆã€‚ç„¶åå°†é…ç½®ä¿å­˜ä¸ºÂ yamlÂ æ–‡ä»¶ï¼Œä»¥ä¾¿ç”¨ä½œæ¨¡å‹èåˆå‘½ä»¤çš„è¾“å…¥ã€‚</p> 
<pre><code>import yaml

MODEL_NAMEÂ =Â "Marcoro14-7B-slerp"
yaml_configÂ =Â """
slices:
Â Â -Â sources:
Â Â Â Â Â Â -Â model:Â AIDC-ai-business/Marcoroni-7B-v3
Â Â Â Â Â Â Â Â layer_range:Â [0,Â 32]
Â Â Â Â Â Â -Â model:Â EmbeddedLLM/Mistral-7B-Merge-14-v0.1
Â Â Â Â Â Â Â Â layer_range:Â [0,Â 32]
merge_method:Â slerp
base_model:Â AIDC-ai-business/Marcoroni-7B-v3
parameters:
Â Â t:
Â Â Â Â -Â filter:Â self_attn
Â Â Â Â Â Â value:Â [0,Â 0.5,Â 0.3,Â 0.7,Â 1]
Â Â Â Â -Â filter:Â mlp
Â Â Â Â Â Â value:Â [1,Â 0.5,Â 0.7,Â 0.3,Â 0]
Â Â Â Â -Â value:Â 0.5
dtype:Â bfloat16

"""

#Â Save config as yaml file
with open('config.yaml',Â 'w',Â encoding="utf-8")Â as f:
Â Â Â Â f.write(yaml_config)
</code></pre> 
<p>æˆ‘ä»¬ä¼šä½¿ç”¨ä»¥ä¸‹å‚æ•°è¿è¡Œæ¨¡å‹èåˆå‘½ä»¤ï¼š</p> 
<ul><li>â€“copy-tokenizerÂ ç”¨äºä»åŸºç¡€æ¨¡å‹å¤åˆ¶åˆ†è¯å™¨</li><li>â€“allow-crimesÂ å’ŒÂ --out-shard-sizeÂ å¯ç”¨äºå°†æ¨¡å‹åˆ’åˆ†ä¸ºè¾ƒå°çš„åˆ†ç‰‡ï¼ˆshardsï¼‰ï¼Œå¯åœ¨å†…å­˜è¾ƒå°çš„Â CPUÂ ä¸Šè¿›è¡Œè®¡ç®—</li><li>â€“lazy-unpickleÂ ç”¨äºå¯ç”¨å®éªŒæ€§çš„lazy unpicklerï¼ˆè¯‘è€…æ³¨ï¼šâ€œlazy unpicklerâ€Â æŒ‡çš„æ˜¯ä¸€ç§å®éªŒæ€§çš„ã€èƒ½å¤Ÿä»¥ä¸€ç§æƒ°æ€§æˆ–å»¶è¿ŸåŠ è½½çš„æ–¹å¼æ‰§è¡Œååºåˆ—åŒ–æ“ä½œçš„æœºåˆ¶ã€‚ï¼‰ï¼Œä»¥é™ä½å†…å­˜ä½¿ç”¨ç‡</li></ul> 
<p>æ­¤å¤–ï¼ŒæŸäº›æ¨¡å‹å¯èƒ½è¿˜éœ€è¦Â --trust_remote_codeÂ å‚æ•°ï¼ˆMistral-7BÂ ä¸éœ€è¦ï¼‰ã€‚</p> 
<p>è¯¥å‘½ä»¤å°†ä¸‹è½½æ¨¡å‹èåˆé…ç½®ä¸­åˆ—å‡ºçš„æ‰€æœ‰æ¨¡å‹çš„æƒé‡ï¼Œå¹¶è¿è¡Œæ‰€é€‰çš„æ¨¡å‹èåˆæ–¹æ³•ï¼ˆåº”è¯¥éœ€è¦çº¦Â 10Â åˆ†é’Ÿï¼‰ã€‚</p> 
<pre><code>#Â Merge models
!mergekit-yaml config.yaml mergeÂ --copy-tokenizerÂ --allow-crimesÂ --out-shard-size 1BÂ --lazy-unpickl
</code></pre> 
<p>ç°åœ¨ï¼Œæ¨¡å‹å·²ç»èåˆå¹¶ä¿å­˜åœ¨Â mergeÂ ç›®å½•ä¸­ã€‚åœ¨ä¸Šä¼ ä¹‹å‰ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªåŒ…å«å¤ç°è¯¥æ¨¡å‹èåˆæ“ä½œæ‰€éœ€ä¿¡æ¯çš„Â README æ–‡ä»¶ã€‚ä»¥ä¸‹ä»£ç å—å®šä¹‰äº†ä¸€ä¸ªÂ JinjaÂ æ¨¡æ¿ï¼Œå¹¶è‡ªåŠ¨å°†æ¨¡å‹èåˆé…ç½®ä¸­çš„æ•°æ®å¡«å…¥å…¶ä¸­ã€‚</p> 
<pre><code>!pip installÂ -qU huggingface_hub

fromÂ huggingface_hubÂ importÂ ModelCard,Â ModelCardData
fromÂ jinja2Â importÂ Template

usernameÂ = "mlabonne"

template_textÂ = """
---
license:Â apache-2.0
tags:
-Â merge
-Â mergekit
-Â lazymergekit
{%-Â for model in modelsÂ %}
-Â {<!-- -->{Â modelÂ }}
{%-Â endforÂ %}
---

#Â {<!-- -->{Â model_nameÂ }}

{<!-- -->{Â model_nameÂ }}Â is a merge of the following models usingÂ [mergekit](https://github.com/cg123/mergekit):

{%-Â for model in modelsÂ %}
*Â [{<!-- -->{Â modelÂ }}](https://huggingface.co/{<!-- -->{Â modelÂ }})
{%-Â endforÂ %}

##Â ğŸ§©Â Configuration

```yaml
{<!-- -->{-Â yaml_configÂ -}}
```
"""

#Â Create a Jinja template object
jinja_templateÂ =Â Template(template_text.strip())

#Â Get list of models from config
dataÂ =Â yaml.safe_load(yaml_config)
if "models" inÂ data:
Â Â Â Â modelsÂ = [data["models"][i]["model"] forÂ iÂ in range(len(data["models"])) if "parameters" inÂ data["models"][i]]
elif "parameters" inÂ data:
Â Â Â Â modelsÂ = [data["slices"][0]["sources"][i]["model"] forÂ iÂ in range(len(data["slices"][0]["sources"]))]
elif "slices" inÂ data:
Â Â Â Â modelsÂ = [data["slices"][i]["sources"][0]["model"] forÂ iÂ in range(len(data["slices"]))]
else:
 raiseÂ Exception("No models or slices found in yaml config")

#Â Fill the template
contentÂ =Â jinja_template.render(
Â Â Â Â model_name=MODEL_NAME,
Â Â Â Â models=models,
Â Â Â Â yaml_config=yaml_config,
Â Â Â Â username=username,
)

#Â Save the model card
cardÂ =Â ModelCard(content)
card.save('merge/README.md')
</code></pre> 
<p>ç°åœ¨æˆ‘ä»¬æœ‰äº†Â model cardÂ ï¼Œå°±å¯ä»¥å°†æ•´ä¸ªæ–‡ä»¶å¤¹æ¨é€åˆ°Â HuggingFace Hubã€‚</p> 
<pre><code>from google.colab import userdata
from huggingface_hub import HfApi

usernameÂ =Â "mlabonne"

#Â Defined in the secrets tab in Google Colab
apiÂ =Â HfApi(token=userdata.get("HF_TOKEN"))

api.create_repo(
Â Â Â Â repo_id=f"{username}/{MODEL_NAME}",
Â Â Â Â repo_type="model"
)
api.upload_folder(
Â Â Â Â repo_id=f"{username}/{MODEL_NAME}",
Â Â Â Â folder_path="merge",
)
</code></pre> 
<p>è¯¥æ¨¡å‹ç°åœ¨å¯ä»¥åœ¨Â Hugging Face HubÂ ä¸Šæ‰¾åˆ°ï¼Œä½äºÂ mlabonne/Marcoro14â€“7B-slerp[25]ã€‚åœ¨å¦ä¸€ä¸ªÂ notebookÂ ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç å°è¯•åœ¨å…è´¹çš„Â T4 GPUÂ ä¸Šè¿è¡Œè¯¥æ¨¡å‹ï¼š</p> 
<pre><code>!pip installÂ -qU transformers accelerate

from transformers import AutoTokenizer
import transformers
import torch

modelÂ =Â "mlabonne/Marcoro14-7B-slerp"
messagesÂ =Â [{"role":Â "user",Â "content":Â "What is a large language model?"}]

tokenizerÂ =Â AutoTokenizer.from_pretrained(model)
promptÂ =Â tokenizer.apply_chat_template(
Â Â Â Â messages,
Â Â Â Â tokenize=False,
Â Â Â Â add_generation_prompt=True
)
pipelineÂ =Â transformers.pipeline(
Â Â Â Â "text-generation",
Â Â Â Â model=model,
Â Â Â Â torch_dtype=torch.float16,
Â Â Â Â device_map="auto",
)

outputsÂ =Â pipeline(prompt,Â max_new_tokens=256,Â do_sample=True,Â temperature=0.7,Â top_k=50,Â top_p=0.95)
</code></pre> 
<p>æˆ‘ä»¬å‘Â LLMÂ æå‡ºäº†"What is a Large Language Model?"è¿™ä¸ªé—®é¢˜ï¼Œå¹¶è·å¾—äº†è¿™æ ·çš„è¾“å‡ºç»“æœï¼š</p> 
<pre><code>A large language model is a type of artificial intelligenceÂ (AI)Â system that has been trained on vast amounts of text data.Â Itâ€™s designed to understand and generate human-like language,Â making predictions on what words or phrases might come next in a sentence or document.Â These models use complex algorithms and neural network architectures to learn from the data and improve their performance over time.Â Some well-known large language models include GPT-3 from OpenAI and BERT from Google.
</code></pre> 
<p>èåˆåçš„æ¨¡å‹çœ‹èµ·æ¥ä¸é”™ï¼Œä½†æˆ‘ä»¬éœ€è¦æ›´å…¨é¢çš„è¯„ä¼°ã€‚å¯¹äºè¿™ç§é€šç”¨å‹æ¨¡å‹ï¼Œæœ‰ä¸€äº›æœ‰è¶£çš„åŸºå‡†æµ‹è¯•ï¼š</p> 
<ol><li>Chatbot Arena[26]ï¼Œå®ƒé€šè¿‡äººç±»çš„æŠ•ç¥¨ç¼–åˆ¶Â LLMsÂ æ’è¡Œæ¦œã€‚äººä»¬å¯¹ä¸åŒè¯­è¨€æ¨¡å‹çš„è¡¨ç°è¿›è¡ŒæŠ•ç¥¨ï¼Œç„¶åä½¿ç”¨Â EloÂ ç®—æ³•å¯¹è¿™äº›æ¨¡å‹è¿›è¡Œæ’åã€‚</li><li>MT-bench[26]ï¼Œå®ƒä½¿ç”¨Â GPT-4Â ä½œä¸ºè¯„åˆ¤å‘˜ï¼Œå¯¹ä¸€ç»„å¤šè½®é—®é¢˜ä¸Šçš„æ¨¡å‹å›ç­”è¿›è¡Œè¯„åˆ†ã€‚</li><li>NousResearch benchmark suite[27]ï¼Œå®ƒæ±‡æ€»äº†å››ä¸ªåŸºå‡†æµ‹è¯•ï¼šAGIEvalã€GPT4ALLã€TruthfulQAÂ å’ŒÂ Bigbenchã€‚GPT4ALLÂ åŒ…æ‹¬äº†Â HellaSwagã€OpenBookQAã€Winograndeã€ARC-Easyã€ARC-Challengeã€BoolQÂ å’ŒÂ PIQAã€‚</li><li>Open LLM Leaderboard[28]ï¼Œå®ƒæ±‡æ€»äº†å…­ä¸ªåŸºå‡†æµ‹è¯•ï¼šARCã€HellaSwagã€MMLUã€Winograndeã€GSM8KÂ å’ŒÂ TruthfulQAã€‚</li></ol> 
<p>ä¸å¹¸çš„æ˜¯ï¼Œæˆ‘ä»¬æ— æ³•å°†è¯¥æ¨¡å‹æäº¤åˆ°Â Chatbot Arenaã€‚ä¸è¿‡ï¼Œå¯ä»¥é€‰æ‹©ä½¿ç”¨Â Open LLM LeaderboardÂ å’ŒÂ NousResearchÂ åŸºå‡†æµ‹è¯•å¯¹å…¶è¿›è¡Œè¯„ä¼°ã€‚</p> 
<p>æˆ‘å·²ç»å°†è¯¥æ¨¡å‹æäº¤åˆ°äº†Â Open LLM Leaderboard[28]ï¼Œå®ƒåœ¨è¯¥æ’è¡Œæ¦œä¸Šè¢«è¯„ä¸ºæœ€ä½³çš„Â 7BÂ å‚æ•°æ¨¡å‹ã€‚ä»¥ä¸‹æ˜¯å…·ä½“æƒ…å†µæˆªå›¾ï¼š</p> 
<p><img src="https://images2.imgbox.com/13/62/IV365l0T_o.png" alt=""></p> 
<p>Image by author</p> 
<p>Open LLM LeaderboardÂ çš„é—®é¢˜åœ¨äºè¿™äº›åŸºå‡†æµ‹è¯•æ˜¯å…¬å¼€çš„ã€‚è¿™æ„å‘³ç€äººä»¬å¯ä»¥åœ¨æµ‹è¯•æ•°æ®ä¸Šè®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œä»¥è·å¾—æ›´å¥½çš„ç»“æœã€‚èåˆè¿™äº›æœ€ä½³çš„æ¨¡å‹ï¼Œä¹Ÿä¼šæ±¡æŸ“æ¨¡å‹ã€‚<strong>å¯ä»¥è‚¯å®šçš„æ˜¯ï¼ŒMarcoro14-7B-slerpÂ å—åˆ°äº†æ±¡æŸ“ï¼Œè€Œä¸”è¿™æ¬¡èåˆä¸­ä½¿ç”¨çš„ä¸€äº›æ¨¡å‹åº”è¯¥æ˜¯åœ¨è¿™äº›è¯„ä¼°æµ‹è¯•é›†ä¸Šè®­ç»ƒè¿‡çš„ã€‚</strong> å¦‚æœä½ æƒ³åˆ›å»ºæœ€å¥½çš„æ¨¡å‹è€Œéä»…ä»…åœ¨æ’è¡Œæ¦œä¸Šè¡¨ç°è¾ƒå¥½çš„æ¨¡å‹ï¼Œæˆ‘å»ºè®®åªä½¿ç”¨éèåˆçš„æ¨¡å‹æ¥åˆ›å»ºè‡ªå·±çš„èåˆæ¨¡å‹ã€‚</p> 
<p>è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬ä¸èƒ½åªä¾èµ–äºÂ Open LLM Leaderboardã€‚åœ¨Â NousResearchÂ benchmark suiteÂ ä¸­ï¼Œæˆ‘ä½¿ç”¨äº†Â ğŸ§Â LLM AutoEvalÂ [29]æ¥è‡ªåŠ¨è®¡ç®—è¯„ä¼°åˆ†æ•°ã€‚ä»¥ä¸‹æ˜¯ä¸è¡¨ç°ä¼˜ç§€çš„Â OpenHermes-2.5-Mistral-7BÂ [30]è¿›è¡Œæ¯”è¾ƒçš„ç»“æœï¼š</p> 
<p><img src="https://images2.imgbox.com/cb/a9/LvnGoE8V_o.png" alt=""></p> 
<p>Image by author</p> 
<p>ä¸è¯¥æ¨¡å‹ç›¸æ¯”ï¼Œæˆ‘ä»¬åœ¨æ¯é¡¹åŸºå‡†æµ‹è¯•ä¸­éƒ½å–å¾—äº†æ˜¾è‘—è¿›æ­¥ã€‚è¯·æ³¨æ„ï¼ŒÂ NousResearchÂ benchmark suiteÂ ä¸Â Open LLM LeaderboardÂ å…±äº«äº†ä¸€äº›è¯„ä¼°ä»»åŠ¡ï¼šARC-Challengeï¼ŒTruthfulQAï¼ŒHellaSwagå’ŒWinograndeã€‚æ®æˆ‘æ‰€çŸ¥ï¼ŒBigbenchæ˜¯å”¯ä¸€å®Œå…¨ä¸åŒçš„åŸºå‡†æµ‹è¯•ï¼ˆå¦‚æœæƒ…å†µä¸æ˜¯è¿™æ ·ï¼Œè¯·éšæ—¶å»åŸæ–‡é“¾æ¥ä¸ä½œè€…è”ç³»ï¼‰ã€‚<strong>ç„¶è€Œï¼Œåœ¨æ­¤æ¬¡æ¨¡å‹èåˆä¸­ä½¿ç”¨çš„æ¨¡å‹ä¹‹ä¸€ä»å¯èƒ½æ˜¯åœ¨Bigbenchçš„è¯„æµ‹æ•°æ®é›†ä¸Šè®­ç»ƒè¿‡çš„ã€‚</strong></p> 
<h2><a id="03__381"></a><strong>03 æ€»ç»“</strong></h2> 
<p>åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä½¿ç”¨å››ç§ä¸åŒçš„æ–¹æ³•å»èåˆÂ LLMsÂ ã€‚è¯¦ç»†è¯´æ˜äº†Â SLERPã€TIESã€DAREÂ å’ŒÂ passthroughÂ çš„å·¥ä½œåŸç†ï¼Œå¹¶æä¾›äº†ç›¸å…³çš„é…ç½®ç¤ºä¾‹ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡Â mergekitÂ åº“ä½¿ç”¨SLERPæ–¹æ³•è®­ç»ƒå‡ºäº†Â Marcoro14â€“7B-slerpÂ ï¼Œå¹¶å°†å…¶ä¸Šä¼ åˆ°Â Hugging Face HubÂ ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªåŸºå‡†å¥—ä»¶ä¸Šéƒ½è·å¾—äº†å‡ºè‰²çš„æ€§èƒ½ï¼šOpen LLM Leaderboardï¼ˆè¯¥æ¨¡å‹æ˜¯è¯¥æ¦œå•æ€§èƒ½æœ€ä½³çš„Â 7BÂ æ¨¡å‹ï¼‰å’ŒNousResearchã€‚</p> 
<p><strong>Thanks for reading!</strong></p> 
<p><strong>END</strong></p> 
<h2><a id="_388"></a><strong>å‚è€ƒèµ„æ–™</strong></h2> 
<p>[1]https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</p> 
<p>[2]https://github.com/cg123/mergekit</p> 
<p>[3]https://huggingface.co/mlabonne/Marcoro14-7B-slerp</p> 
<p>[4]https://github.com/mlabonne/llm-course/blob/main/Mergekit.ipynb</p> 
<p>[5]https://colab.research.google.com/drive/1_JS7JKJAQozD48-LhYdegcuuZ2ddgXfr?usp=sharing</p> 
<p>[6]https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing</p> 
<p>[7]https://www.linkedin.com/in/charles-goddard-7b6797b/</p> 
<p>[8]https://github.com/cg123/mergekit/tree/1011ef3a84e4c5545473602baf7ef32d535044a9#linear</p> 
<p>[9]https://arxiv.org/abs/2212.04089</p> 
<p>[10]https://huggingface.co/collections/osanseviero/model-merging-65097893623330a3a51ead66</p> 
<p>[11]https://huggingface.co/EmbeddedLLM/Mistral-7B-Merge-14-v0.1</p> 
<p>[12]https://huggingface.co/OpenPipe/mistral-ft-optimized-1218</p> 
<p>[13]https://huggingface.co/mlabonne/NeuralHermes-2.5-Mistral-7B</p> 
<p>[14]https://huggingface.co/mlabonne/NeuralPipe-7B-slerp</p> 
<p>[15]https://arxiv.org/abs/2306.01708</p> 
<p>[16]https://huggingface.co/Weyaxi/OpenHermes-2.5-neural-chat-7b-v3-1-7B</p> 
<p>[17]https://huggingface.co/mlabonne/NeuralPipe-7B-ties</p> 
<p>[18]https://arxiv.org/abs/2311.03099</p> 
<p>[19]https://github.com/cg123/mergekit/issues/26</p> 
<p>[20]https://huggingface.co/mlabonne/Daredevil-7B</p> 
<p>[21]https://huggingface.co/zyh3826/GML-Mistral-merged-v1</p> 
<p>[22]https://huggingface.co/mlabonne/NeuralPipe-9B-merged</p> 
<p>[23]https://huggingface.co/AIDC-ai-business/Marcoroni-7B-v3</p> 
<p>[24]https://huggingface.co/EmbeddedLLM/Mistral-7B-Merge-14-v0.1</p> 
<p>[25]https://huggingface.co/mlabonne/Marcoro14-7B-slerp</p> 
<p>[26]https://chat.lmsys.org/</p> 
<p>[27]https://github.com/teknium1/LLM-Benchmark-Logs</p> 
<p>[28]https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</p> 
<p>[29]https://github.com/mlabonne/llm-autoeval</p> 
<p>[30]https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B</p> 
<p><strong>åŸæ–‡é“¾æ¥ï¼š</strong></p> 
<p>https://towardsdatascience.com/merge-large-language-models-with-mergekit-2118fb392b54</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3a18189bcbdfb3937e6606403527ed28/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">æ¯å¤©ä¸€ä¸ªæ•°æ®åˆ†æé¢˜ï¼ˆä¸€ç™¾å…­åå››ï¼‰</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b91e04830843906eaebe377249541337/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">ä¸€äº›å†…ç½‘æ¸—é€æ€»ç»“</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 è¿½é£å°‘å¹´çš„åšå®¢.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>