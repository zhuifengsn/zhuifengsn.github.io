<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python爬虫爬取图片 必应&amp;百度（仅供学习） - 追风少年的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="python爬虫爬取图片 必应&amp;百度（仅供学习）" />
<meta property="og:description" content="简介 分别在 必应 和 百度 中爬取图片的代码，只需要将搜索关键字改成你需要爬取的关键字即可复用
在必应中爬取图片 话不多说，先上代码
import requests from bs4 import BeautifulSoup import os def get_image_urls(query, num_images,j): url = f&#34;https://www.bing.com/images/async?q={query}&amp;first={j}&amp;count={num_images}&#34; response = requests.get(url) soup = BeautifulSoup(response.text, &#34;html.parser&#34;) image_tags = soup.find_all(&#34;img&#34;, class_=&#34;mimg&#34;) filtered_image_tags = [img for img in image_tags if &#34;vimgld&#34; not in img[&#34;class&#34;]] image_urls = [img[&#34;src&#34;] for img in filtered_image_tags] return image_urls def download_images(image_urls, save_dir,j): if not os.path.exists(save_dir): os.makedirs(save_dir) for i, url in enumerate(image_urls): response = requests.get(url) with open(f&#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zhuifengsn.github.io/posts/6a5405ac67f170d3819f52e461d4a87a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-02-16T13:23:03+08:00" />
<meta property="article:modified_time" content="2024-02-16T13:23:03+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="追风少年的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">追风少年的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python爬虫爬取图片 必应&amp;百度（仅供学习）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>简介</h2> 
<p>分别在 必应 和 百度 中爬取图片的代码，只需要将搜索关键字改成你需要爬取的关键字即可复用</p> 
<h2>在必应中爬取图片</h2> 
<p>话不多说，先上代码</p> 
<pre><code class="language-python">import requests
from bs4 import BeautifulSoup
import os

def get_image_urls(query, num_images,j):
    url = f"https://www.bing.com/images/async?q={query}&amp;first={j}&amp;count={num_images}"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")
    image_tags = soup.find_all("img", class_="mimg")
    filtered_image_tags = [img for img in image_tags if "vimgld" not in img["class"]]
    image_urls = [img["src"] for img in filtered_image_tags]
    return image_urls

def download_images(image_urls, save_dir,j):
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    for i, url in enumerate(image_urls):
        response = requests.get(url)
        with open(f"{save_dir}/image_{j}_{i}.jpg", "wb") as f:
            f.write(response.content)

if __name__ == "__main__":
    query = "皮卡丘"
    num_images = 10
    save_dir = "皮卡丘图片"
    for j in range(999):
        image_urls = get_image_urls(query, num_images ,j)
        download_images(image_urls, save_dir,j)
</code></pre> 
<p>在以上代码中，我们的URL是</p> 
<pre><code class="language-python">url = f"https://www.bing.com/images/async?q={query}&amp;first={j}&amp;count={num_images}"</code></pre> 
<p>在浏览器中搜索一下，可以发现<span style="color:#fe2c24;">q代表搜索关键词，first是页数，count是每页多少张图片</span>因此我们</p> 
<p> 代码中定义query = "皮卡丘"  num_images = 10 然后 写一个for循环，给first={j}赋值</p> 
<p><img alt="" height="663" src="https://images2.imgbox.com/10/32/Qsi4f6cF_o.png" width="1200"></p> 
<p>因为在代码运行中发现一部分图片class=“mimg vimgld” 是受保护的，我们获取这些图片的话会报错，所以使用代码</p> 
<pre><code class="language-python">filtered_image_tags = [img for img in image_tags if "vimgld" not in img["class"]]</code></pre> 
<p>将他们排除掉 </p> 
<p><img alt="" height="554" src="https://images2.imgbox.com/b0/3d/vFxN3xYo_o.png" width="966"></p> 
<p>然后就可以保存我们的图片了，save_dir的值就是设置我们保存图片的文件夹，我这里设置成皮卡丘图片，然后运行项目，该项目的根目录下就会创建一个文件夹，爬取到的图片都会存储在这个文件夹中</p> 
<p><img alt="" height="687" src="https://images2.imgbox.com/9f/6b/ufSN4i5N_o.png" width="1059"></p> 
<h2>在百度中爬虫图片</h2> 
<p>先上代码</p> 
<pre><code class="language-python">import re, requests, time  # 导入所需要的库

headers = {
    "User-Agent": "Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.106 Mobile Safari/537.36",
    "Cookie": "BAIDUID=229A18B7534A5CEA671381D45FCDC530:FG=1; BIDUPSID=229A18B7534A5CEA671381D45FCDC530; PSTM=1592693385; BDRCVFR[dG2JNJb_ajR]=mk3SLVN4HKm; userFrom=null; BDRCVFR[-pGxjrCMryR]=mk3SLVN4HKm; H_WISE_SIDS=149389_148867_148211_149537_146732_138426_150175_147527_145599_148186_147715_149253_150045_149280_145607_148660_146055_110085; delPer=0; BDORZ=AE84CDB3A529C0F8A2B9DCDD1D18B695; ysm=10315; IMG_WH=626_611; __bsi=8556698095607456048_00_14_R_R_17_0303_c02f_Y",
}
name = "皮卡丘"  # 搜索图片的关键字
file = "皮卡丘图片2"  # 存储图片的文件夹
detail_urls = []  # 存储图片地址
for i in range(1, 400, 20):  # 20页一张
    url = 'http://image.baidu.com/search/flip?tn=baiduimage&amp;ipn=r&amp;ct=201326592&amp;cl=2&amp;lm=&amp;st=-1&amp;fm=result&amp;fr=&amp;sf=1&amp;fmq=1592804203005_R&amp;pv=&amp;ic=&amp;nc=1&amp;z=&amp;hd=&amp;latest=&amp;copyright=&amp;se=1&amp;showtab=0&amp;fb=0&amp;width=&amp;height=&amp;face=0&amp;istype=2&amp;ie=utf-8&amp;ctd=1592804203008%5E00_1328X727&amp;sid=&amp;word={}&amp;pn={}'.format(
        name, i)  # 请求的地址
    response = requests.get(url, headers, timeout=(3, 7))  # 设置请求超时时间3-7秒
    content = response.content.decode('utf-8')  # 使用utf-8进行解码
    detail_url = re.findall('"objURL":"(.*?)"', content, re.DOTALL)  # re.DOTALL忽略格式#匹配objURL的内容,大部分为objURL或URL
    detail_urls.append(detail_url)  # 将获取到的图片地址保存在之前定义的列表中
    response = requests.get(url, headers=headers)  # 请求网站
    content = response.content

b = 0  # 图片第几张
for page in detail_urls:
    for url in page:
        try:
            response = requests.get(url, headers=headers)
            content = response.content
            if url[-3:] == 'jpg':
                with open('{}\{}{}.jpg'.format(file, name, b), 'wb') as f:
                    f.write(content)
            elif url[-4:] == 'jpeg':
                with open('{}\{}{}.jpeg'.format(file, name, b), 'wb') as f:
                    f.write(content)
            elif url[-3:] == 'png':
                with open('{}\{}{}.pon'.format(file, name, b), 'wb') as f:
                    f.write(content)
            else:
                continue

        except:
            print('超时')
        b += 1
        print('获取到第{}张图片'.format(b))
</code></pre> 
<p>许多网站有能力识别非正常浏览器的访问行为。如果一个请求看起来像是来自爬虫而非浏览器，服务器可能会拒绝这个请求，返回403错误响应码。通过在headers中模拟浏览器的用户代理（User-Agent），可以让请求看起来像是来自真实的浏览器，从而避免被网站的反爬机制拦截</p> 
<p>打开浏览器，按下F12在请求头，搜索任意图片，找到第一条http请求，我们找到User-Agent:和Cookie:然后将上面代码中的 headers={ }中的内容替换成你自己的</p> 
<p><img alt="" height="1087" src="https://images2.imgbox.com/db/68/WwjAFbEw_o.png" width="1200"></p> 
<p>name变量即是你在搜索框输入的内容，然后file就是爬到的图片保存的路径，执行代码后会根据你设置的file在根目录创建文件夹存放爬取的图片</p> 
<p><img alt="" height="885" src="https://images2.imgbox.com/50/44/E5wlZxrd_o.png" width="1190"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a99124607a5b06ec0670b48ecf3af97a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">[职场] 会计学专业学什么 #其他#知识分享#职场发展</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8edea449114ee052ebde4f8764beba2e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">spring boot 使用AOP实现是否已登录检测</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 追风少年的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>