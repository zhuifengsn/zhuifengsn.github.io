<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>推荐系统实战——新闻推荐数据分析 - 追风少年的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="推荐系统实战——新闻推荐数据分析" />
<meta property="og:description" content="数据分析 数据分析的价值主要在于熟悉了解整个数据集的基本情况包括每个文件里有哪些数据，具体的文件中的每个字段表示什么实际含义，以及数据集中特征之间的相关性，在推荐场景下主要就是分析用户本身的基本属性，文章基本属性，以及用户和文章交互的一些分布，这些都有利于后面的召回策略的选择，以及特征工程。
建议：当特征工程和模型调参已经很难继续上分了，可以回来在重新从新的角度去分析这些数据，或许可以找到上分的灵感
导包 # 导入相关包 %matplotlib inline import pandas as pd import numpy as np ​ import matplotlib.pyplot as plt import seaborn as sns plt.rc(&#39;font&#39;, family=&#39;SimHei&#39;, size=13) ​ import os,gc,re,warnings,sys warnings.filterwarnings(&#34;ignore&#34;) 读取数据 path = &#39;./data_raw/&#39; ​ #####train trn_click = pd.read_csv(path&#43;&#39;train_click_log.csv&#39;) item_df = pd.read_csv(path&#43;&#39;articles.csv&#39;) item_df = item_df.rename(columns={&#39;article_id&#39;: &#39;click_article_id&#39;}) #重命名，方便后续match item_emb_df = pd.read_csv(path&#43;&#39;articles_emb.csv&#39;) ​ #####test tst_click = pd.read_csv(path&#43;&#39;testA_click_log.csv&#39;) 数据预处理 计算用户点击rank和点击次数
# 对每个用户的点击时间戳进行排序 trn_click[&#39;rank&#39;] = trn_click.groupby([&#39;user_id&#39;])[&#39;click_timestamp&#39;].rank(ascending=False).astype(int) tst_click[&#39;rank&#39;] = tst_click.groupby([&#39;user_id&#39;])[&#39;click_timestamp&#39;].rank(ascending=False).astype(int) #计算用户点击文章的次数，并添加新的一列count trn_click[&#39;click_cnts&#39;] = trn_click." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zhuifengsn.github.io/posts/1b2fd9e1ef221d30c5180716e6c2e8ac/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-27T15:06:40+08:00" />
<meta property="article:modified_time" content="2020-11-27T15:06:40+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="追风少年的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">追风少年的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">推荐系统实战——新闻推荐数据分析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>数据分析</h3> 
<p>数据分析的价值主要在于熟悉了解整个数据集的基本情况包括每个文件里有哪些数据，具体的文件中的每个字段表示什么实际含义，以及数据集中特征之间的相关性，在推荐场景下主要就是分析用户本身的基本属性，文章基本属性，以及用户和文章交互的一些分布，这些都有利于后面的召回策略的选择，以及特征工程。</p> 
<p><strong>建议：当特征工程和模型调参已经很难继续上分了，可以回来在重新从新的角度去分析这些数据，或许可以找到上分的灵感</strong></p> 
<h3>导包</h3> 
<pre><code class="language-html hljs"># 导入相关包
%matplotlib inline
import pandas as pd
import numpy as np
​
import matplotlib.pyplot as plt
import seaborn as sns
plt.rc('font', family='SimHei', size=13)
​
import os,gc,re,warnings,sys
warnings.filterwarnings("ignore")</code></pre> 
<h3>读取数据</h3> 
<pre><code class="language-html hljs">path = './data_raw/'
​
#####train
trn_click = pd.read_csv(path+'train_click_log.csv')
item_df = pd.read_csv(path+'articles.csv')
item_df = item_df.rename(columns={'article_id': 'click_article_id'})  #重命名，方便后续match
item_emb_df = pd.read_csv(path+'articles_emb.csv')
​
#####test
tst_click = pd.read_csv(path+'testA_click_log.csv')</code></pre> 
<h3>数据预处理</h3> 
<p>计算用户点击rank和点击次数</p> 
<pre><code class="language-html hljs"># 对每个用户的点击时间戳进行排序
trn_click['rank'] = trn_click.groupby(['user_id'])['click_timestamp'].rank(ascending=False).astype(int)
tst_click['rank'] = tst_click.groupby(['user_id'])['click_timestamp'].rank(ascending=False).astype(int)</code></pre> 
<pre><code class="language-html hljs">#计算用户点击文章的次数，并添加新的一列count
trn_click['click_cnts'] = trn_click.groupby(['user_id'])['click_timestamp'].transform('count')
tst_click['click_cnts'] = tst_click.groupby(['user_id'])['click_timestamp'].transform('count')</code></pre> 
<p> </p> 
<h3>数据浏览</h3> 
<h4>用户点击日志文件_训练集</h4> 
<pre><code class="language-html hljs">trn_click = trn_click.merge(item_df, how='left', on=['click_article_id'])
trn_click.head()</code></pre> 
<p><img alt="image-20201119112706647" src="https://images2.imgbox.com/63/75/pW6CCe3S_o.png"></p> 
<p><strong>train_click_log.csv文件数据中每个字段的含义</strong></p> 
<ol><li> <p>user_id: 用户的唯一标识</p> </li><li> <p>click_article_id: 用户点击的文章唯一标识</p> </li><li> <p>click_timestamp: 用户点击文章时的时间戳</p> </li><li> <p>click_environment: 用户点击文章的环境</p> </li><li> <p>click_deviceGroup: 用户点击文章的设备组</p> </li><li> <p>click_os: 用户点击文章时的操作系统</p> </li><li> <p>click_country: 用户点击文章时的所在的国家</p> </li><li> <p>click_region: 用户点击文章时所在的区域</p> </li><li> <p>click_referrer_type: 用户点击文章时，文章的来源</p> </li></ol> 
<pre><code class="language-html hljs">#用户点击日志信息
trn_click.info()</code></pre> 
<p><img alt="image-20201119112622939" src="https://images2.imgbox.com/db/f0/lpVaQSVz_o.png"></p> 
<p> </p> 
<pre><code class="language-html hljs">trn_click.describe()</code></pre> 
<p><img alt="image-20201119112649376" src="https://images2.imgbox.com/c8/e9/o29NDcMs_o.png"></p> 
<pre><code class="language-html hljs">#训练集中的用户数量为20w
trn_click.user_id.nunique()</code></pre> 
<pre><code class="language-html hljs">200000</code></pre> 
<pre><code class="language-html hljs">trn_click.groupby('user_id')['click_article_id'].count().min()  # 训练集里面每个用户至少点击了两篇文章</code></pre> 
<pre><code class="language-html hljs">2</code></pre> 
<p><strong>画直方图大体看一下基本的属性分布</strong></p> 
<pre><code class="language-html hljs">plt.figure()
plt.figure(figsize=(15, 20))
i = 1
for col in ['click_article_id', 'click_timestamp', 'click_environment', 'click_deviceGroup', 'click_os', 'click_country', 
            'click_region', 'click_referrer_type', 'rank', 'click_cnts']:
    plot_envs = plt.subplot(5, 2, i)
    i += 1
    v = trn_click[col].value_counts().reset_index()[:10]
    fig = sns.barplot(x=v['index'], y=v[col])
    for item in fig.get_xticklabels():
        item.set_rotation(90)
    plt.title(col)
plt.tight_layout()
plt.show()</code></pre> 
<p><img alt="在这里插入图片描述" src="https://images2.imgbox.com/a7/1d/lZhLI7FZ_o.png"></p> 
<p><strong>从点击时间clik_timestamp来看，分布较为平均，可不做特殊处理。由于时间戳是13位的，后续将时间格式转换成10位方便计算。</strong></p> 
<p><strong>从点击环境click_environment来看，仅有1922次（占0.1%）点击环境为1；仅有24617次（占2.3%）点击环境为2；剩余（占97.6%）点击环境为4。</strong></p> 
<p><strong>从点击设备组click_deviceGroup来看，设备1占大部分（60.4%），设备3占36%。</strong></p> 
<h4>测试集用户点击日志</h4> 
<pre><code class="language-html hljs">tst_click = tst_click.merge(item_df, how='left', on=['click_article_id'])
tst_click.head()</code></pre> 
<p><img alt="image-20201119112952261" src="https://images2.imgbox.com/05/ff/tKHsxioA_o.png"></p> 
<pre><code class="language-html hljs">tst_click.describe()</code></pre> 
<p><img alt="image-20201119113015529" src="https://images2.imgbox.com/4e/a8/QW7yuAp6_o.png"></p> 
<p><strong>我们可以看出训练集和测试集的用户是完全不一样的</strong></p> 
<p><strong>训练集的用户ID由0 ~ 199999，而测试集A的用户ID由200000 ~ 249999。</strong></p> 
<pre><code class="language-html hljs">#测试集中的用户数量为5w
tst_click.user_id.nunique()</code></pre> 
<pre><code class="language-html hljs">50000</code></pre> 
<pre><code class="language-html hljs">tst_click.groupby('user_id')['click_article_id'].count().min() # 注意测试集里面有只点击过一次文章的用户</code></pre> 
<pre><code class="language-html hljs">1</code></pre> 
<h4>新闻文章信息数据表</h4> 
<pre><code class="language-html hljs">#新闻文章数据集浏览
item_df.head().append(item_df.tail())</code></pre> 
<p><img alt="image-20201119113118388" src="https://images2.imgbox.com/7d/ae/OaVptvCh_o.png"></p> 
<pre><code class="language-html hljs">item_df['words_count'].value_counts()</code></pre> 
<p><img alt="image-20201119113147240" src="https://images2.imgbox.com/a4/e0/WP9tHPpC_o.png"></p> 
<pre><code class="language-html hljs">print(item_df['category_id'].nunique())     # 461个文章主题
item_df['category_id'].hist()</code></pre> 
<p> </p> 
<pre><code class="language-html hljs">item_df.shape       # 364047篇文章</code></pre> 
<pre><code class="language-html hljs">(364047, 4)</code></pre> 
<h4>新闻文章embedding向量表示</h4> 
<pre><code class="language-html hljs">item_emb_df.head()</code></pre> 
<p><img alt="image-20201119113253455" src="https://images2.imgbox.com/d8/36/0iTcHCsZ_o.png"></p> 
<pre><code class="language-html hljs">item_emb_df.shape</code></pre> 
<pre><code class="language-html hljs">(364047, 251)</code></pre> 
<h3>数据分析</h3> 
<h4>用户重复点击</h4> 
<pre><code class="language-html hljs">#####merge
user_click_merge = trn_click.append(tst_click)</code></pre> 
<pre><code class="language-html hljs">#用户重复点击
user_click_count = user_click_merge.groupby(['user_id', 'click_article_id'])['click_timestamp'].agg({'count'}).reset_index()
user_click_count[:10]</code></pre> 
<p><img alt="image-20201119113334727" src="https://images2.imgbox.com/6a/fb/om1EkbSh_o.png"></p> 
<pre><code class="language-html hljs">user_click_count[user_click_count['count']&gt;7]</code></pre> 
<p><img alt="image-20201119113351807" src="https://images2.imgbox.com/96/74/PBqFrDvR_o.png"></p> 
<pre><code class="language-html hljs">user_click_count['count'].unique()</code></pre> 
<p><img alt="image-20201119113429769" src="https://images2.imgbox.com/c5/0d/etwrpbN5_o.png"></p> 
<pre><code class="language-html hljs">#用户点击新闻次数
user_click_count.loc[:,'count'].value_counts() </code></pre> 
<p><img alt="image-20201119113414785" src="https://images2.imgbox.com/85/57/nrcoJn0U_o.png"></p> 
<p><strong>可以看出：有1605541（约占99.2%）的用户未重复阅读过文章，仅有极少数用户重复点击过某篇文章。 这个也可以单独制作成特征</strong></p> 
<h4>用户点击环境变化分析</h4> 
<pre><code class="language-html hljs">def plot_envs(df, cols, r, c):
    plt.figure()
    plt.figure(figsize=(10, 5))
    i = 1
    for col in cols:
        plt.subplot(r, c, i)
        i += 1
        v = df[col].value_counts().reset_index()
        fig = sns.barplot(x=v['index'], y=v[col])
        for item in fig.get_xticklabels():
            item.set_rotation(90)
        plt.title(col)
    plt.tight_layout()
    plt.show()</code></pre> 
<pre><code class="language-html hljs"># 分析用户点击环境变化是否明显，这里随机采样10个用户分析这些用户的点击环境分布
sample_user_ids = np.random.choice(tst_click['user_id'].unique(), size=5, replace=False)
sample_users = user_click_merge[user_click_merge['user_id'].isin(sample_user_ids)]
cols = ['click_environment','click_deviceGroup', 'click_os', 'click_country', 'click_region','click_referrer_type']
for _, user_df in sample_users.groupby('user_id'):
    plot_envs(user_df, cols, 2, 3)</code></pre> 
<p><img alt="image-20201119113624424" src="https://images2.imgbox.com/96/85/XdLqa9Fi_o.png"></p> 
<p><img alt="image-20201119113637746" src="https://images2.imgbox.com/fe/31/ihBqO75H_o.png"></p> 
<p><img alt="image-20201119113652132" src="https://images2.imgbox.com/03/49/EUYCV48K_o.png"></p> 
<p><img alt="image-20201119113702034" src="https://images2.imgbox.com/a4/52/UfiOuT05_o.png"></p> 
<p><img alt="image-20201119113714135" src="https://images2.imgbox.com/e4/f5/p1gSzZnF_o.png"></p> 
<p><strong>可以看出绝大多数数的用户的点击环境是比较固定的。思路：可以基于这些环境的统计特征来代表该用户本身的属性</strong></p> 
<h4>用户点击新闻数量的分布</h4> 
<pre><code class="language-html hljs">user_click_item_count = sorted(user_click_merge.groupby('user_id')['click_article_id'].count(), reverse=True)
plt.plot(user_click_item_count)</code></pre> 
<p><img alt="image-20201119113759490" src="https://images2.imgbox.com/ec/da/u6EUxZKr_o.png"></p> 
<p><strong>可以根据用户的点击文章次数看出用户的活跃度</strong></p> 
<pre><code class="language-html hljs">#点击次数在前50的用户
plt.plot(user_click_item_count[:50])</code></pre> 
<p><img alt="image-20201119113825586" src="https://images2.imgbox.com/78/ec/TQCHZvsd_o.png"></p> 
<p><strong>点击次数排前50的用户的点击次数都在100次以上。思路：我们可以定义点击次数大于等于100次的用户为活跃用户，这是一种简单的处理思路， 判断用户活跃度，更加全面的是再结合上点击时间，后面我们会基于点击次数和点击时间两个方面来判断用户活跃度。</strong></p> 
<pre><code class="language-html hljs">#点击次数排名在[25000:50000]之间
plt.plot(user_click_item_count[25000:50000])</code></pre> 
<p><img alt="image-20201119113844946" src="https://images2.imgbox.com/51/a9/vLJkE1ux_o.png"></p> 
<p><strong>可以看出点击次数小于等于两次的用户非常的多，这些用户可以认为是非活跃用户</strong></p> 
<h4>新闻点击次数分析</h4> 
<pre><code class="language-html hljs">item_click_count = sorted(user_click_merge.groupby('click_article_id')['user_id'].count(), reverse=True)</code></pre> 
<pre><code class="language-html hljs">plt.plot(item_click_count)</code></pre> 
<p><img alt="image-20201119113912912" src="https://images2.imgbox.com/e8/ec/PgDWPMwv_o.png"></p> 
<pre><code class="language-html hljs">plt.plot(item_click_count[:100])</code></pre> 
<p><img alt="image-20201119113930745" src="https://images2.imgbox.com/ef/40/iq4aDqbA_o.png"></p> 
<p><strong>可以看出点击次数最多的前100篇新闻，点击次数大于1000次</strong></p> 
<pre><code class="language-html hljs">plt.plot(item_click_count[:20])</code></pre> 
<p><img alt="image-20201119113958254" src="https://images2.imgbox.com/3b/b1/iy9Nj4zS_o.png"></p> 
<p><strong>点击次数最多的前20篇新闻，点击次数大于2500。思路：可以定义这些新闻为热门新闻， 这个也是简单的处理方式，后面我们也是根据点击次数和时间进行文章热度的一个划分。</strong></p> 
<pre><code class="language-html hljs">plt.plot(item_click_count[3500:])</code></pre> 
<p><img alt="image-20201119114017762" src="https://images2.imgbox.com/2b/d0/YNt8OwV1_o.png"></p> 
<p><strong>可以发现很多新闻只被点击过一两次。思路：可以定义这些新闻是冷门新闻。</strong></p> 
<h4>新闻共现频次：两篇新闻连续出现的次数</h4> 
<pre><code class="language-html hljs">tmp = user_click_merge.sort_values('click_timestamp')
tmp['next_item'] = tmp.groupby(['user_id'])['click_article_id'].transform(lambda x:x.shift(-1))
union_item = tmp.groupby(['click_article_id','next_item'])['click_timestamp'].agg({'count'}).reset_index().sort_values('count', ascending=False)
union_item[['count']].describe()</code></pre> 
<p><img alt="image-20201119114044351" src="https://images2.imgbox.com/c5/82/Tu0xgMFc_o.png"></p> 
<p><strong>由统计数据可以看出，平均共现次数2.88，最高为1687。</strong></p> 
<p><strong>说明用户看的新闻，相关性是比较强的。</strong></p> 
<pre><code class="language-html hljs">#画个图直观地看一看
x = union_item['click_article_id']
y = union_item['count']
plt.scatter(x, y)</code></pre> 
<p><img alt="image-20201119114106223" src="https://images2.imgbox.com/0a/ec/4rq6Jv6b_o.png"></p> 
<pre><code class="language-html hljs">plt.plot(union_item['count'].values[40000:])</code></pre> 
<p><img alt="image-20201119114122557" src="https://images2.imgbox.com/f9/da/d6uRwkpB_o.png"></p> 
<p><strong>大概有70000个pair至少共现一次。</strong></p> 
<p> </p> 
<h4>新闻文章信息</h4> 
<pre><code class="language-html hljs">#不同类型的新闻出现的次数
plt.plot(user_click_merge['category_id'].value_counts().values)</code></pre> 
<p><img alt="image-20201119114144058" src="https://images2.imgbox.com/a3/4b/U97lEvsL_o.png"></p> 
<pre><code class="language-html hljs">#出现次数比较少的新闻类型, 有些新闻类型，基本上就出现过几次
plt.plot(user_click_merge['category_id'].value_counts().values[150:])</code></pre> 
<p><img alt="image-20201119114201764" src="https://images2.imgbox.com/e3/9d/m7b68XVb_o.png"></p> 
<pre><code class="language-html hljs">#新闻字数的描述性统计
user_click_merge['words_count'].describe()</code></pre> 
<p> </p> 
<pre><code class="language-html hljs">plt.plot(user_click_merge['words_count'].values)</code></pre> 
<p><img alt="image-20201119114241194" src="https://images2.imgbox.com/65/38/UbKVNoda_o.png"></p> 
<p> </p> 
<h4>用户点击的新闻类型的偏好</h4> 
<p>此特征可以用于度量用户的兴趣是否广泛。</p> 
<pre><code class="language-html hljs">plt.plot(sorted(user_click_merge.groupby('user_id')['category_id'].nunique(), reverse=True))</code></pre> 
<p><img alt="image-20201119114300286" src="https://images2.imgbox.com/cd/df/TNorokXs_o.png"></p> 
<p><strong>从上图中可以看出有一小部分用户阅读类型是极其广泛的，大部分人都处在20个新闻类型以下。</strong></p> 
<pre><code class="language-html hljs">user_click_merge.groupby('user_id')['category_id'].nunique().reset_index().describe()</code></pre> 
<p><img alt="image-20201119114318523" src="https://images2.imgbox.com/72/9e/aqQwyns9_o.png"></p> 
<h4>用户查看文章的长度的分布</h4> 
<p>通过统计不同用户点击新闻的平均字数，这个可以反映用户是对长文更感兴趣还是对短文更感兴趣。</p> 
<pre><code class="language-html hljs">plt.plot(sorted(user_click_merge.groupby('user_id')['words_count'].mean(), reverse=True))</code></pre> 
<p><img alt="image-20201119114337448" src="https://images2.imgbox.com/82/1e/2nM3eIYS_o.png"></p> 
<p> </p> 
<p><strong>从上图中可以发现有一小部分人看的文章平均词数非常高，也有一小部分人看的平均文章次数非常低。</strong></p> 
<p><strong>大多数人偏好于阅读字数在200-400字之间的新闻。</strong></p> 
<pre><code class="language-html hljs">#挑出大多数人的区间仔细看看
plt.plot(sorted(user_click_merge.groupby('user_id')['words_count'].mean(), reverse=True)[1000:45000])</code></pre> 
<p><img alt="image-20201119114355195" src="https://images2.imgbox.com/b5/f8/Uwm4yaa5_o.png"></p> 
<p><strong>可以发现大多数人都是看250字以下的文章</strong></p> 
<pre><code class="language-html hljs">#更加详细的参数
user_click_merge.groupby('user_id')['words_count'].mean().reset_index().describe()</code></pre> 
<p><img alt="image-20201119114418911" src="https://images2.imgbox.com/7c/9e/wIAPPKBT_o.png"></p> 
<p> </p> 
<h4>用户点击新闻的时间分析</h4> 
<pre><code class="language-html hljs">#为了更好的可视化，这里把时间进行归一化操作
from sklearn.preprocessing import MinMaxScaler
mm = MinMaxScaler()
user_click_merge['click_timestamp'] = mm.fit_transform(user_click_merge[['click_timestamp']])
user_click_merge['created_at_ts'] = mm.fit_transform(user_click_merge[['created_at_ts']])

user_click_merge = user_click_merge.sort_values('click_timestamp')</code></pre> 
<pre><code class="language-html hljs">user_click_merge.head()</code></pre> 
<p><img alt="image-20201119114447904" src="https://images2.imgbox.com/2f/db/dRU2EB5J_o.png"></p> 
<pre><code class="language-html hljs">def mean_diff_time_func(df, col):
    df = pd.DataFrame(df, columns={col})
    df['time_shift1'] = df[col].shift(1).fillna(0)
    df['diff_time'] = abs(df[col] - df['time_shift1'])
    return df['diff_time'].mean()</code></pre> 
<pre><code class="language-html hljs"># 点击时间差的平均值
mean_diff_click_time = user_click_merge.groupby('user_id')['click_timestamp', 'created_at_ts'].apply(lambda x: mean_diff_time_func(x, 'click_timestamp'))</code></pre> 
<pre><code class="language-html hljs">plt.plot(sorted(mean_diff_click_time.values, reverse=True))</code></pre> 
<p><img alt="image-20201119114505086" src="https://images2.imgbox.com/aa/f7/w9ntk8rT_o.png"></p> 
<p><strong>从上图可以发现不同用户点击文章的时间差是有差异的。</strong></p> 
<pre><code class="language-html hljs"># 前后点击文章的创建时间差的平均值
mean_diff_created_time = user_click_merge.groupby('user_id')['click_timestamp', 'created_at_ts'].apply(lambda x: mean_diff_time_func(x, 'created_at_ts'))</code></pre> 
<pre><code class="language-html hljs">plt.plot(sorted(mean_diff_created_time.values, reverse=True))</code></pre> 
<p><img alt="image-20201119122227666" src="https://images2.imgbox.com/b7/09/a8Gvuhvr_o.png"></p> 
<p><strong>从图中可以发现用户先后点击文章，文章的创建时间也是有差异的</strong></p> 
<pre><code class="language-html hljs"># 用户前后点击文章的相似性分布
item_idx_2_rawid_dict = dict(zip(item_emb_df['article_id'], item_emb_df.index))</code></pre> 
<pre><code class="language-html hljs">del item_emb_df['article_id']</code></pre> 
<pre><code class="language-html hljs">item_emb_np = np.ascontiguousarray(item_emb_df.values, dtype=np.float32)</code></pre> 
<pre><code class="language-html hljs"># 随机选择5个用户，查看这些用户前后查看文章的相似性
sub_user_ids = np.random.choice(user_click_merge.user_id.unique(), size=15, replace=False)
sub_user_info = user_click_merge[user_click_merge['user_id'].isin(sub_user_ids)]

sub_user_info.head()</code></pre> 
<p><img alt="image-20201119122251274" src="https://images2.imgbox.com/58/a4/TxnsjyDt_o.png"></p> 
<pre><code class="language-html hljs">def get_item_sim_list(df):
    sim_list = []
    item_list = df['click_article_id'].values
    for i in range(0, len(item_list)-1):
        emb1 = item_emb_np[item_idx_2_rawid_dict[item_list[i]]]
        emb2 = item_emb_np[item_idx_2_rawid_dict[item_list[i+1]]]
        sim_list.append(np.dot(emb1,emb2)/(np.linalg.norm(emb1)*(np.linalg.norm(emb2))))
    sim_list.append(0)
    return sim_list</code></pre> 
<pre><code class="language-html hljs">for _, user_df in sub_user_info.groupby('user_id'):
    item_sim_list = get_item_sim_list(user_df)
    plt.plot(item_sim_list)</code></pre> 
<p><img alt="image-20201119122310969" src="https://images2.imgbox.com/b6/55/kJy6LaN2_o.png"></p> 
<p> </p> 
<p><strong>从图中可以看出有些用户前后看的商品的相似度波动比较大，有些波动比较小，也是有一定的区分度的。</strong></p> 
<p> </p> 
<h3>总结</h3> 
<p>通过数据分析的过程， 我们目前可以得到以下几点重要的信息， 这个对于我们进行后面的特征制作和分析非常有帮助：</p> 
<ol><li> <p>训练集和测试集的用户id没有重复，也就是测试集里面的用户没有模型是没有见过的</p> </li><li> <p>训练集中用户最少的点击文章数是2， 而测试集里面用户最少的点击文章数是1</p> </li><li> <p>用户对于文章存在重复点击的情况， 但这个都存在于训练集里面</p> </li><li> <p>同一用户的点击环境存在不唯一的情况，后面做这部分特征的时候可以采用统计特征</p> </li><li> <p>用户点击文章的次数有很大的区分度，后面可以根据这个制作衡量用户活跃度的特征</p> </li><li> <p>文章被用户点击的次数也有很大的区分度，后面可以根据这个制作衡量文章热度的特征</p> </li><li> <p>用户看的新闻，相关性是比较强的，所以往往我们判断用户是否对某篇文章感兴趣的时候， 在很大程度上会和他历史点击过的文章有关</p> </li><li> <p>用户点击的文章字数有比较大的区别， 这个可以反映用户对于文章字数的区别</p> </li><li> <p>用户点击过的文章主题也有很大的区别， 这个可以反映用户的主题偏好 10.不同用户点击文章的时间差也会有所区别， 这个可以反映用户对于文章时效性的偏好</p> </li></ol> 
<p>所以根据上面的一些分析，可以更好的帮助我们后面做好特征工程， 充分挖掘数据的隐含信息。</p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5826a88befec7774b4ade3f8bb0472bc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">期望值（Expect value）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b29b70dd9a5a161440de685e34a799fb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Qt控件美化 用好CSS/QSS可视化工具</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 追风少年的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>