<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【Python奇淫技巧】用pandas的read_html函数仅一行代码实现网页爬虫 - 追风少年的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【Python奇淫技巧】用pandas的read_html函数仅一行代码实现网页爬虫" />
<meta property="og:description" content="目录
一、介绍read_html()函数
二、分析爬取目标页面
三、代码讲解
四、同步视频讲解
一、介绍read_html()函数 喜欢Python编程的小伙伴你知道吗，python的pandas库除了可以做数据分析，还可以做简易爬虫，仅需一行核心代码，就可以实现一个爬虫程序，轻轻松松爬取网页数据！
它就是pandas库的read_html()函数，实现python爬虫可以说是非常方便了。
这里需要说明的是，它只能针对网页上有&lt;table&gt;&lt;/table&gt;标签的表格数据进行爬取。
二、分析爬取目标页面 这里，我爬取的目标网址是：上海市天气预报_某网站
可以看到，页面上是有一个表格数据的，按F12打开开发者模式，查看网页源代码：
确实是有&lt;table&gt;标签的表格数据。那就好办了，开始撸代码！
三、代码讲解 代码总共3行，核心代码就1行：
import pandas as pd # 导入库 url = &#39;http://weather.sina.com.cn/china/shanghaishi/&#39; # 目标网址(含有&lt;table&gt;的表格) df = pd.read_html(url)[1] # 开始爬取目标网站 这样短短3行代码，数据就爬取下来了。看一下爬下来的数据：
没问题，和原页面数据完全一致！后面在用pd.to_excel()把数据保存下来就OK了。
超级简单、强大有没有！
这里附上read_html()函数的官网参数说明，供小伙伴们参考：（贴心的我已经翻译成中文了^_^）
再次强调一遍，它只能针对网页上有&lt;table&gt;&lt;/table&gt;标签的表格数据进行爬取。
如果页面上没有&lt;table&gt;标签，用这个方法爬取的话，会提示&#34;No tables found&#34;的报错：
这是我用ipython界面截的图，用其他IDE也会这样报错的！
四、同步视频讲解 代码逐行讲解视频：
【爬虫神器】2分钟讲解用python一行代码轻松爬取网页数据
按以往的习惯，我都会分享Python源码文件，这次不用分享了吧，就3行代码，自己撸吧小伙伴！
同步公众号文章：
【Python爬虫奇淫技巧】 用pandas库read_html函数一行代码搞定爬虫！
我是马哥，全网累计粉丝上万，欢迎一起交流python技术。
各平台搜索“马哥python说”：知乎、哔哩哔哩、小红书、新浪微博。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zhuifengsn.github.io/posts/33995d7a7a107bb79c41473163dfc365/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-17T11:33:35+08:00" />
<meta property="article:modified_time" content="2022-04-17T11:33:35+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="追风少年的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">追风少年的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【Python奇淫技巧】用pandas的read_html函数仅一行代码实现网页爬虫</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="h_445464339_0-toc" style="margin-left:0px;"><a href="#h_445464339_0" rel="nofollow">一、介绍read_html()函数</a></p> 
<p id="h_445464339_1-toc" style="margin-left:0px;"><a href="#h_445464339_1" rel="nofollow">二、分析爬取目标页面</a></p> 
<p id="h_445464339_2-toc" style="margin-left:0px;"><a href="#h_445464339_2" rel="nofollow">三、代码讲解</a></p> 
<p id="%E5%9B%9B%E3%80%81%E5%90%8C%E6%AD%A5%E8%A7%86%E9%A2%91%E8%AE%B2%E8%A7%A3-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%E5%90%8C%E6%AD%A5%E8%A7%86%E9%A2%91%E8%AE%B2%E8%A7%A3" rel="nofollow">四、同步视频讲解</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2>一、介绍read_html()函数</h2> 
<p>喜欢Python编程的小伙伴你知道吗，python的pandas库除了可以做数据分析，还可以做简易爬虫，仅需一行核心代码，就可以实现一个爬虫程序，轻轻松松爬取网页数据！</p> 
<p>它就是<strong>pandas库的read_html()函数</strong>，实现python爬虫可以说是非常方便了。</p> 
<p>这里需要说明的是，<strong>它只能针对网页上有&lt;table&gt;&lt;/table&gt;标签的表格数据进行爬取。</strong></p> 
<h2 id="h_445464339_1">二、分析爬取目标页面</h2> 
<p>这里，我爬取的目标网址是：<strong>上海市天气预报_某网站</strong></p> 
<p>可以看到，页面上是有一个表格数据的，按F12打开开发者模式，查看网页源代码：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/36/29/OGD7Kfdx_o.png"></p> 
<p>确实是<strong>有&lt;table&gt;标签的表格数据</strong>。那就好办了，开始撸代码！</p> 
<h2 id="h_445464339_2">三、代码讲解</h2> 
<p>代码总共3行，核心代码就1行：</p> 
<pre><code class="language-python">import pandas as pd   # 导入库
url = 'http://weather.sina.com.cn/china/shanghaishi/'  # 目标网址(含有&lt;table&gt;的表格)
df = pd.read_html(url)[1]  # 开始爬取目标网站</code></pre> 
<p>这样短短3行代码，数据就爬取下来了。看一下爬下来的数据：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/eb/d4/NKsZvA5b_o.png"></p> 
<p>没问题，和原页面数据完全一致！后面在用pd.to_excel()把数据保存下来就OK了。</p> 
<p>超级简单、强大有没有！</p> 
<p>这里附上<strong>read_html()函数的官网参数说明</strong>，供小伙伴们参考：（贴心的我已经翻译成中文了^_^）</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/6d/34/ViYGNzHZ_o.jpg" width="1200"></p> 
<p>再次强调一遍，<strong>它只能针对网页上有&lt;table&gt;&lt;/table&gt;标签的表格数据进行爬取。</strong></p> 
<p>如果页面上没有&lt;table&gt;标签，用这个方法爬取的话，会提示"<strong>No tables found</strong>"的报错：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/42/95/EWi3oLh7_o.png"></p> 
<p><strong>这是我用ipython界面截的图，用其他IDE也会这样报错的！</strong></p> 
<h2 id="%E5%9B%9B%E3%80%81%E5%90%8C%E6%AD%A5%E8%A7%86%E9%A2%91%E8%AE%B2%E8%A7%A3"><strong>四、同步视频讲解</strong></h2> 
<p>代码逐行讲解视频：</p> 
<div class="csdn-video-box"> 
 <iframe id="ApGW1PBi-1650161146361" frameborder="0" src="https://live.csdn.net/v/embed/198871" allowfullscreen="true" data-mediaembed="csdn"></iframe> 
 <p>【爬虫神器】2分钟讲解用python一行代码轻松爬取网页数据</p> 
</div> 
<p></p> 
<p>按以往的习惯，我都会分享Python源码文件，这次不用分享了吧，就3行代码，自己撸吧小伙伴！</p> 
<p>同步公众号文章：</p> 
<p><a href="https://mp.weixin.qq.com/s?__biz=MzU5MjQ2MzI0Nw==&amp;mid=2247483951&amp;idx=1&amp;sn=dd0d607fafacce6a503632c010bc46f9&amp;chksm=fe1e16cfc9699fd997c6d01a3de260bf9c1f327bc93d012e380ee1c2f9c27294d89ecc66545f&amp;token=928226833&amp;lang=zh_CN#rd" rel="nofollow" title="【Python爬虫奇淫技巧】 用pandas库read_html函数一行代码搞定爬虫！">【Python爬虫奇淫技巧】 用pandas库read_html函数一行代码搞定爬虫！</a></p> 
<hr> 
<p><strong>我是马哥，全网累计粉丝上万，欢迎一起交流python技术。</strong></p> 
<p><strong>各平台搜索“<span style="color:#fe2c24;">马哥python说</span>”：知乎、哔哩哔哩、小红书、新浪微博。</strong></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4faeae57954ba7791df1e887828c3ac4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">docker离线安装方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/11477b2360831076fb182e233df748e4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Google中国编程挑战赛入围赛真题HardDuplicateRemover(1000分)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 追风少年的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>